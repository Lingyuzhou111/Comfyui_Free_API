import os
import json
import base64
import requests
from PIL import Image
from io import BytesIO
import re

# èŠ‚ç‚¹ä¸»ç±»
class OpenAIImageAPI:
    """
    ComfyUIè‡ªå®šä¹‰èŠ‚ç‚¹ï¼šOpenAIå…¼å®¹å›¾åƒAPI
    å®ç°å›¾åƒç”Ÿæˆå’Œå›¾åƒç¼–è¾‘çš„é€šç”¨APIè°ƒç”¨ï¼Œæ”¯æŒå¤šç§APIæ ¼å¼ï¼š
    1. ä¼ ç»Ÿimages/generationsç«¯ç‚¹ï¼ˆOpenAIã€é­”æ­ã€SiliconFlowã€ç«å±±æ–¹èˆŸç­‰ï¼‰
    2. chat/completionsç«¯ç‚¹ï¼ˆä½¿ç”¨äºä½¿ç”¨èŠå¤©æ ¼å¼çš„å›¾åƒç”Ÿæˆå¹³å°ï¼‰
    
    è¾“å…¥å‚æ•°ï¼šbase_url, model, api_key, user_prompt, image1-4(å¯é€‰), size, num_images, api_endpoint
    è¾“å‡ºï¼šimageï¼ˆç”Ÿæˆçš„å›¾åƒï¼‰, generation_infoï¼ˆç”Ÿæˆä¿¡æ¯ï¼ŒåŒ…å«image_urlå’Œtotal_tokensï¼‰
    
    æ”¯æŒåŠŸèƒ½ï¼š
    - æ–‡ç”Ÿå›¾ï¼šçº¯æ–‡æœ¬æç¤ºè¯ç”Ÿæˆå›¾åƒ
    - å›¾ç”Ÿå›¾ï¼šåŸºäºè¾“å…¥å›¾åƒå’Œæç¤ºè¯ç”Ÿæˆæ–°å›¾åƒ
    - å¤šå¹³å°å…¼å®¹ï¼šè‡ªåŠ¨é€‚é…ä¸åŒå¹³å°çš„APIæ ¼å¼å·®å¼‚
    """
    def __init__(self):
        # å»¶è¿ŸåŠ è½½ratioæ˜ å°„ï¼Œé¿å…å¯¼å…¥é˜¶æ®µå› æ–‡ä»¶ç¼ºå¤±æŠ¥é”™
        self._ratio_map = None
        self._resolution_keys = ["1k", "1.5k", "2k", "4k"]
        self._ratio_keys = ["1:1", "2:3", "3:4", "4:3", "3:2", "16:9", "9:16", "21:9"]

    def _load_ratio_map(self):
        """
        ä»åŒç›®å½•çš„ratio_map.jsonè¯»å–åˆ†è¾¨ç‡ä¸æ¯”ä¾‹æ˜ å°„ã€‚
        æ–‡ä»¶ç»“æ„åº”åŒ…å«å››ä¸ªåˆ†è¾¨ç‡é”®ï¼š1kã€1.5kã€2kã€4kï¼›æ¯ä¸ªé”®ä¸‹åŒ…å«å…«ç§æ¯”ä¾‹ã€‚
        """
        if self._ratio_map is not None:
            return self._ratio_map
        try:
            current_dir = os.path.dirname(__file__)
            json_path = os.path.join(current_dir, "ratio_map.json")
            with open(json_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            # æŒ‰å®é™…æ–‡ä»¶ç»“æ„æ ¡éªŒï¼š*_ratios é”®ï¼Œä»¥åŠå…¶ä¸‹çš„æ¯”ä¾‹é”®
            required_ratio_keys = ("1k_ratios", "1.5k_ratios", "2k_ratios", "4k_ratios")
            for rk in required_ratio_keys:
                if rk not in data:
                    raise ValueError(f"ratio_map.jsonç¼ºå°‘é”®: {rk}")
                for pk in self._ratio_keys:
                    if pk not in data[rk]:
                        raise ValueError(f"ratio_map.jsonçš„{rk}ç¼ºå°‘æ¯”ä¾‹é”®: {pk}")
            self._ratio_map = data
            return self._ratio_map
        except Exception as e:
            print(f"[OpenAIImageAPI] è¯»å–ratio_map.jsonå¤±è´¥: {e}")
            # å¤±è´¥æ—¶æä¾›å›é€€ï¼šç”¨å¹³æ–¹åƒç´ å ä½ï¼Œä¿è¯èŠ‚ç‚¹å¯ç”¨
            fallback = {}
            # ç®€å•çš„å›é€€æ•°å€¼ï¼ˆéç¡¬ç¼–ç å›ºå®šåœ¨INPUT_TYPESä¸­ï¼Œä»…ä½œä¸ºè¿è¡Œæ—¶å…œåº•ï¼‰
            fallback_sizes = {
                "1k": {"1:1": "1024x1024", "2:3": "896x1344", "3:4": "960x1280", "4:3": "1280x960", "3:2": "1344x896", "16:9": "1536x864", "9:16": "864x1536", "21:9": "1792x768"},
                "1.5k": {"1:1": "1328x1328", "2:3": "1104x1656", "3:4": "1200x1600", "4:3": "1600x1200", "3:2": "1656x1104", "16:9": "1856x1044", "9:16": "1044x1856", "21:9": "2208x944"},
                "2k": {"1:1": "1664x1664", "2:3": "1472x2208", "3:4": "1536x2048", "4:3": "2048x1536", "3:2": "2208x1472", "16:9": "2368x1332", "9:16": "1332x2368", "21:9": "2944x1260"},
                "4k": {"1:1": "3072x3072", "2:3": "2688x4032", "3:4": "2880x3840", "4:3": "3840x2880", "3:2": "4032x2688", "16:9": "4096x2304", "9:16": "2304x4096", "21:9": "5376x2304"}
            }
            self._ratio_map = fallback
            return self._ratio_map

    @classmethod
    def INPUT_TYPES(cls):
        """
        æ³¨æ„ï¼šComfyUIåœ¨ç±»æ–¹æ³•ä¸­æ— æ³•ç›´æ¥è®¿é—®å®ä¾‹æˆå‘˜ï¼Œå› æ­¤æˆ‘ä»¬æä¾›ä¸€ä¸ªé™æ€å…œåº•é›†åˆã€‚
        çœŸæ­£çš„åˆ†è¾¨ç‡/æ¯”ä¾‹æ˜ å°„åœ¨è¿è¡Œæ—¶é€šè¿‡_generate_size_from_ratioåŠ è½½ratio_map.jsonã€‚
        ä¸‹æ‹‰ä»…å±•ç¤ºå›ºå®šçš„å››æ¡£resolutionä¸å…«ç§ratioé€‰é¡¹ï¼Œå€¼æœ€ç»ˆä¼šé€šè¿‡æ˜ å°„è½¬ä¸ºsizeåƒç´ ä¸²ã€‚
        """
        return {
            "required": {
                "api_endpoint": (["images/generations", "chat/completions"], {"default": "images/generations"}),
                "base_url": ("STRING", {"default": "https://api.openai.com/v1", "multiline": False}),
                "model": ("STRING", {"default": "dall-e-3", "multiline": False}),
                "api_key": ("STRING", {"default": "", "multiline": False}),
                "user_prompt": ("STRING", {"multiline": True, "default": "ç”Ÿæˆä¸€åªå¯çˆ±çš„å°çŒ«"}),
                "resolution": (["1k", "1.5k", "2k", "4k", "gpt4o"], {"default": "1k"}),
                # æ³¨æ„ï¼šå½“é€‰æ‹© gpt4o æ—¶ï¼Œä»… 1:1ã€2:3ã€3:2 æœ‰æ•ˆï¼Œå…¶å®ƒæ¯”ä¾‹ä¼šåœ¨è¿è¡Œæ—¶è¢«æ˜ å°„æ ¡éªŒæ‹¦æˆª
                "ratio": (["1:1", "2:3", "3:4", "4:3", "3:2", "16:9", "9:16", "21:9"], {"default": "1:1"}),
                "num_images": ("INT", {"default": 1, "min": 1, "max": 4, "step": 1}),
            },
            "optional": {
                "image1": ("IMAGE",),
                "image2": ("IMAGE",),
                "image3": ("IMAGE",),
                "image4": ("IMAGE",),
                "image5": ("IMAGE",),
                "image6": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("image", "generation_info")
    FUNCTION = "generate_image"
    CATEGORY = "ğŸ¦‰FreeAPI/OpenAI"

    def generate_image(self, base_url, model, api_key, user_prompt, resolution, ratio, num_images, api_endpoint, image1=None, image2=None, image3=None, image4=None, image5=None, image6=None):
        """
        ä¸»å›¾åƒç”Ÿæˆæ–¹æ³•ï¼š
        1. æ ¹æ®æ˜¯å¦æœ‰è¾“å…¥å›¾åƒå†³å®šæ˜¯å›¾åƒç”Ÿæˆè¿˜æ˜¯å›¾åƒç¼–è¾‘
        2. æ„é€ OpenAIå…¼å®¹çš„å›¾åƒAPIè¯·æ±‚
        3. å‘é€è¯·æ±‚ï¼Œè¿”å›å›¾åƒ
        4. è§£æå“åº”å¹¶è¿”å›å›¾åƒæ•°æ®
        """
        if not api_key:
            empty_image = self._create_empty_image()
            if empty_image is None:
                import torch
                empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
            return (empty_image, "é”™è¯¯ï¼šæœªé…ç½®API Keyï¼Œè¯·åœ¨èŠ‚ç‚¹å‚æ•°ä¸­è®¾ç½®api_key")
        
        if not base_url:
            empty_image = self._create_empty_image()
            if empty_image is None:
                import torch
                empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
            return (empty_image, "é”™è¯¯ï¼šæœªé…ç½®base_urlï¼Œè¯·åœ¨èŠ‚ç‚¹å‚æ•°ä¸­è®¾ç½®base_url")
        
        # å°† resolution + ratio è½¬ä¸ºå…·ä½“åƒç´ ä¸² size
        size = self._generate_size_from_ratio(resolution, ratio)

        # éªŒè¯gpt-image-1æ¨¡å‹çš„å°ºå¯¸é™åˆ¶
        if model == "gpt-image-1":
            valid_sizes = ["1024x1024", "1536x1024", "1024x1536"]
            if size not in valid_sizes:
                empty_image = self._create_empty_image()
                if empty_image is None:
                    import torch
                    empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                return (empty_image, f"é”™è¯¯ï¼šgpt-image-1æ¨¡å‹ä»…æ”¯æŒå°ºå¯¸ {valid_sizes}ï¼Œå½“å‰å°ºå¯¸ï¼š{size}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å…¥å›¾åƒï¼Œå†³å®šä½¿ç”¨å“ªä¸ªAPIç«¯ç‚¹
        input_images = [img for img in [image1, image2, image3, image4, image5, image6] if img is not None]
        
        # æ ¹æ®é€‰æ‹©çš„APIç«¯ç‚¹å†³å®šè¯·æ±‚æ–¹å¼
        if api_endpoint == "chat/completions":
            # ä½¿ç”¨chat/completionsç«¯ç‚¹
            return self._chat_completions_request(base_url, model, api_key, user_prompt, input_images, size, num_images)
        else:
            # ä½¿ç”¨ä¼ ç»Ÿçš„imagesç«¯ç‚¹
            if input_images:
                # å›¾åƒç¼–è¾‘æ¨¡å¼
                return self._edit_images(base_url, model, api_key, user_prompt, input_images, size)
            else:
                # å›¾åƒç”Ÿæˆæ¨¡å¼
                return self._images_generations_request(base_url, model, api_key, user_prompt, size, num_images)

    def _images_generations_request(self, base_url, model, api_key, user_prompt, size, num_images):
        """
        å›¾åƒç”Ÿæˆæ¨¡å¼
        """
        try:
            # æ ¹æ®APIç«¯ç‚¹é€‰æ‹©åˆé€‚çš„è¯·æ±‚æ ¼å¼
            api_url = f"{base_url.rstrip('/')}/images/generations"

            # æ£€æµ‹ä¸åŒå¹³å°çš„APIç±»å‹å¹¶è®¾ç½®å¯¹åº”çš„response_format
            is_modelscope = "modelscope.cn" in base_url
            is_siliconflow = "siliconflow.cn" in base_url
            is_volcengine = "volces.com" in base_url
            
            # ä¸ºä¸åŒå¹³å°è®¾ç½®å›ºå®šçš„response_format
            if is_modelscope or is_siliconflow or is_volcengine:
                response_format = "url"  # å…¶ä»–å¹³å°é»˜è®¤è¿”å›URL
            else:
                response_format = "b64_json"  # OpenAIå…¼å®¹APIé»˜è®¤è¿”å›base64
            
            if is_modelscope:
                # é­”æ­å¹³å°APIæ ¼å¼
                payload = {
                    "model": model,
                    "prompt": user_prompt,
                    "n": num_images,
                    "size": size,
                    'steps': 30,
                    'guidance': 4.0
                }
            elif is_siliconflow:
                # SiliconFlowå¹³å°APIæ ¼å¼
                payload = {
                    "model": model,
                    "prompt": user_prompt,
                    "image_size": size,
                    "batch_size": num_images,
                    "num_inference_steps": 20, # å›ºå®šå€¼
                    "guidance_scale": 7.5 # å›ºå®šå€¼
                }
            elif is_volcengine:
                # ç«å±±æ–¹èˆŸå¹³å°APIæ ¼å¼
                # è‹¥ä¸º Seedream4.0ï¼ˆæ–‡ç”Ÿå›¾ï¼‰æŒ‰ç¤ºä¾‹è¿›è¡Œå®šåˆ¶ï¼Œå¦åˆ™ä¿æŒé€šç”¨
                is_seedream = model in ("doubao-seedream-4-0-250828", "seedream-4.0", "doubao-seedream-4-0")
                if is_seedream:
                    # å‚è€ƒç”¨æˆ·ç¤ºä¾‹ï¼š/api/v3/images/generations ä½†æœ¬èŠ‚ç‚¹ç»Ÿä¸€èµ° /images/generations è·¯å¾„
                    # è®¾ç½®é¡ºåºç”Ÿæˆå¼€å…³ä¸æ•°é‡ï¼Œå…¼å®¹ num_images å‚æ•°
                    max_images = int(num_images) if isinstance(num_images, int) and num_images > 0 else 1
                    payload = {
                        "model": model,
                        "prompt": user_prompt,
                        "sequential_image_generation": "auto",  # ä¸ç¤ºä¾‹ä¸€è‡´ï¼ˆç¤ºä¾‹æœ‰ä¸¤å¤„ï¼Œæœ€ç»ˆä»¥disabledä¸ºå‡†ï¼‰
                        "sequential_image_generation_options": {"max_images": max_images},
                        "size": size,
                        "stream": False,
                        "response_format": "url",
                        "watermark": False
                    }
                else:
                    payload = {
                        "model": model,
                        "prompt": user_prompt,
                        "response_format": response_format,
                        "size": size,
                        "guidance_scale": 3,  # å›ºå®šå€¼
                        "watermark": False     # å›ºå®šå€¼
                    }
            else:
                # OpenAIå…¼å®¹æ ¼å¼
                payload = {
                    "model": model,
                    "prompt": user_prompt,
                    "n": num_images,
                    "size": size,
                    "response_format": response_format
                }
           
            # å‘é€è¯·æ±‚
            headers = self._build_headers(api_key)
            # é­”æ­å¹³å°å»ºè®®ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼Œä»¥é€‚é…å¦‚ Qwen/Qwen-Image ç­‰éœ€è¦ task_id è½®è¯¢çš„æ¨¡å‹
            if is_modelscope:
                headers["X-ModelScope-Async-Mode"] = "true"
            print(f"[OpenAIImageAPI] æ­£åœ¨è¯·æ±‚å›¾åƒç”ŸæˆAPI: {api_url}")
            print(f"[OpenAIImageAPI] è¯·æ±‚å‚æ•°: model={model}, size={size}, n={num_images}")
            if is_modelscope:
                print(f"[OpenAIImageAPI] APIç±»å‹: é­”æ­å¹³å°")
            elif is_siliconflow:
                print(f"[OpenAIImageAPI] APIç±»å‹: SiliconFlowå¹³å°")
                print(f"[OpenAIImageAPI] SiliconFlowå‚æ•°: num_inference_steps={20}, guidance_scale={7.5}")
            elif is_volcengine:
                print(f"[OpenAIImageAPI] APIç±»å‹: ç«å±±æ–¹èˆŸå¹³å°")
                print(f"[OpenAIImageAPI] ç«å±±æ–¹èˆŸå‚æ•°: guidance_scale={3}, watermark=False")
            else:
                print(f"[OpenAIImageAPI] APIç±»å‹: OpenAIå…¼å®¹")
            #print(f"[OpenAIImageAPI] è¯·æ±‚å¤´: {headers}")
            print(f"[OpenAIImageAPI] è¯·æ±‚è½½è·: {self._safe_json_dumps(payload)}")
            
            resp = requests.post(api_url, headers=headers, json=payload, timeout=300)
            
            # ä¸ç«‹å³æŠ›å‡ºå¼‚å¸¸ï¼Œè®©åç»­é€»è¾‘å¤„ç†å“åº”
            print(f"[OpenAIImageAPI] å“åº”çŠ¶æ€ç : {resp.status_code}")
            #print(f"[OpenAIImageAPI] å“åº”å¤´: {dict(resp.headers)}")

            # é­”æ­å¹³å°éƒ¨åˆ†æ¨¡å‹ï¼ˆå¦‚ Qwen/Qwen-Imageï¼‰ä¼šè¿”å› task_idï¼Œéœ€è¦è½®è¯¢ä»»åŠ¡ç»“æœ
            if is_modelscope:
                try:
                    data = resp.json()
                    print(f"[OpenAIImageAPI] é­”æ­åˆå§‹å“åº”: {self._safe_json_dumps(data)}")
                except Exception:
                    data = None

                # 400 æ—¶ï¼Œå°è¯•ä½¿ç”¨æœ€å°è½½è·è¿›è¡Œä¸€æ¬¡é‡è¯•ï¼ˆä»… model + promptï¼‰
                if resp.status_code == 400:
                    try:
                        minimal_payload = {
                            "model": model,
                            "prompt": user_prompt
                        }
                        print("æ£€æµ‹åˆ° 400ï¼Œä½¿ç”¨æœ€å°å‚æ•°é‡è¯•é­”æ­æäº¤...")
                        print(f"[OpenAIImageAPI] æœ€å°è½½è·: {self._safe_json_dumps(minimal_payload)}")
                        resp_retry = requests.post(api_url, headers=headers, json=minimal_payload, timeout=300)
                        print(f"[OpenAIImageAPI] é‡è¯•å“åº”çŠ¶æ€ç : {resp_retry.status_code}")
                        print(f"[OpenAIImageAPI] é‡è¯•å“åº”å¤´: {dict(resp_retry.headers)}")
                        try:
                            data_retry = resp_retry.json()
                            print(f"[OpenAIImageAPI] é‡è¯•å“åº”JSON: {self._safe_json_dumps(data_retry)}")
                        except Exception:
                            data_retry = None
                        # è‹¥æ‹¿åˆ° task_idï¼Œè¿›å…¥è½®è¯¢
                        if data_retry and isinstance(data_retry, dict) and data_retry.get("task_id"):
                            return self._poll_modelscope_task(base_url, data_retry.get("task_id"), api_key)
                        # å¦åˆ™èµ°é€šç”¨è§£æ
                        return self._parse_image_response(resp_retry)
                    except Exception as _:
                        # é‡è¯•è¿‡ç¨‹å¤±è´¥åˆ™ç»§ç»­èµ°é€šç”¨å¤„ç†
                        pass

                # é¦–æ¬¡å“åº”å°±åŒ…å« task_idï¼Œç›´æ¥è½®è¯¢
                if data and isinstance(data, dict) and data.get("task_id"):
                    return self._poll_modelscope_task(base_url, data.get("task_id"), api_key)

                # å¦åˆ™èµ°é€šç”¨è§£æï¼ˆæ”¯æŒéƒ¨åˆ†æ¨¡å‹ç›´æ¥åŒæ­¥è¿”å› imagesï¼‰
                return self._parse_image_response(resp)

            # éé­”æ­å¹³å°ç›´æ¥æŒ‰é€šç”¨è§£æ
            return self._parse_image_response(resp)
                
        except Exception as e:
            empty_image = self._create_empty_image()
            if empty_image is None:
                import torch
                empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
            return (empty_image, f"å›¾åƒç”Ÿæˆå¤±è´¥: {e}")

    def _chat_completions_request(self, base_url, model, api_key, user_prompt, input_images, size, num_images):
        """
        ä½¿ç”¨chat/completionsç«¯ç‚¹è¿›è¡Œå›¾åƒç”Ÿæˆï¼ˆæ”¯æŒæ–‡ç”Ÿå›¾å’Œå›¾ç”Ÿå›¾ï¼‰
        é€‚ç”¨äºä½¿ç”¨OpenAIèŠå¤©æ ¼å¼çš„å›¾åƒç”Ÿæˆå¹³å°
        """
        try:
            # æ„å»ºAPIç«¯ç‚¹URL
            api_url = f"{base_url.rstrip('/')}/chat/completions"
            
            print(f"[OpenAIImageAPI] æ­£åœ¨è¯·æ±‚Chat Completions API: {api_url}")
            print(f"[OpenAIImageAPI] è¯·æ±‚å‚æ•°: model={model}, è¾“å…¥å›¾åƒæ•°é‡={len(input_images)}")
            
            # æ„å»ºæ¶ˆæ¯å†…å®¹
            content = [{"type": "text", "text": user_prompt}]
            
            # å¦‚æœæœ‰è¾“å…¥å›¾åƒï¼Œæ·»åŠ åˆ°æ¶ˆæ¯å†…å®¹ä¸­ï¼ˆå›¾ç”Ÿå›¾æ¨¡å¼ï¼‰
            if input_images:
                print(f"[OpenAIImageAPI] å›¾ç”Ÿå›¾æ¨¡å¼: å¤„ç† {len(input_images)} å¼ è¾“å…¥å›¾åƒ")
                for i, img in enumerate(input_images):
                    try:
                        # å°†å›¾åƒè½¬æ¢ä¸ºPIL Image
                        pil_image = self._convert_to_pil(img)
                        
                        # è½¬æ¢ä¸ºbase64
                        img_buffer = BytesIO()
                        pil_image.save(img_buffer, format="PNG")
                        img_buffer.seek(0)
                        
                        image_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
                        base64_url = f"data:image/png;base64,{image_base64}"
                        
                        # æ·»åŠ å›¾åƒåˆ°æ¶ˆæ¯å†…å®¹
                        content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": base64_url,
                                "detail": "high"
                            }
                        })
                        
                        print(f"[OpenAIImageAPI] å›¾åƒ{i+1}å¤„ç†æˆåŠŸ: å°ºå¯¸={pil_image.size}, base64é•¿åº¦={len(image_base64)}")
                        
                    except Exception as e:
                        print(f"[OpenAIImageAPI] å›¾åƒ{i+1}å¤„ç†å¤±è´¥: {e}")
                        empty_image = self._create_empty_image()
                        if empty_image is None:
                            import torch
                            empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                        return (empty_image, f"å›¾åƒ{i+1}å¤„ç†å¤±è´¥: {e}")
            else:
                print(f"[OpenAIImageAPI] æ–‡ç”Ÿå›¾æ¨¡å¼: çº¯æ–‡æœ¬æç¤ºè¯ç”Ÿæˆ")
            
            # æ„å»ºè¯·æ±‚è½½è·ï¼ˆå‚è€ƒlmarena-api.jsçš„æ ¼å¼ï¼‰
            # ç§»é™¤ temperature å’Œ max_tokensï¼Œé¿å…è§¦å‘ä¸å¿…è¦çš„ã€å¯èƒ½å› UIå˜åŒ–è€Œå¤±è´¥çš„é¡µé¢äº¤äº’
            # è®©ä»£ç†æœåŠ¡å™¨ä½¿ç”¨AI Studioé¡µé¢çš„é»˜è®¤å€¼
            payload = {
                "model": model,
                "messages": [{
                    "role": "user",
                    "content": content
                }]
            }
            
            # å‘é€è¯·æ±‚
            headers = self._build_headers(api_key)
            print(f"[OpenAIImageAPI] è¯·æ±‚è½½è·: {self._safe_json_dumps(payload)}")
            
            resp = requests.post(api_url, headers=headers, json=payload, timeout=300)
            
            print(f"[OpenAIImageAPI] å“åº”çŠ¶æ€ç : {resp.status_code}")
            print(f"[OpenAIImageAPI] å“åº”å¤´: {dict(resp.headers)}")
            
            # è§£æchat/completionsæ ¼å¼çš„å“åº”
            return self._parse_chat_completions_response(resp)
                
        except Exception as e:
            empty_image = self._create_empty_image()
            if empty_image is None:
                import torch
                empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
            return (empty_image, f"Chat Completionsè¯·æ±‚å¤±è´¥: {e}")

    def _edit_images(self, base_url, model, api_key, user_prompt, input_images, size):
        """
        å›¾åƒç¼–è¾‘æ¨¡å¼
        """
        try:
            # æ£€æµ‹æ˜¯å¦æ˜¯ç«å±±æ–¹èˆŸå¹³å°API
            is_volcengine = "volces.com" in base_url
            
            if is_volcengine:
                # ç«å±±æ–¹èˆŸå¹³å°å›¾ç”Ÿå›¾API
                return self._edit_images_volcengine(base_url, model, api_key, user_prompt, input_images, size)
            else:
                # å…¶ä»–å¹³å°çš„å›¾åƒç¼–è¾‘API
                return self._edit_images_standard(base_url, model, api_key, user_prompt, input_images, size)
                
        except Exception as e:
            empty_image = self._create_empty_image()
            if empty_image is None:
                import torch
                empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
            return (empty_image, f"å›¾åƒç¼–è¾‘å¤±è´¥: {e}")

    def _edit_images_volcengine(self, base_url, model, api_key, user_prompt, input_images, size):
        """
        ç«å±±æ–¹èˆŸå¹³å°å›¾åƒç¼–è¾‘æ¨¡å¼ï¼ˆæ”¯æŒ Seedream4.0 å¤šå›¾å‚è€ƒï¼‰
        """
        try:
            headers = self._build_headers(api_key)
            api_url = f"{base_url.rstrip('/')}/images/generations"
            
            print(f"[OpenAIImageAPI] æ­£åœ¨è¯·æ±‚ç«å±±æ–¹èˆŸå›¾åƒç¼–è¾‘API: {api_url}")
            print(f"[OpenAIImageAPI] è¯·æ±‚å‚æ•°: model={model}, è¾“å…¥å›¾åƒæ•°é‡={len(input_images)}")
            
            if not input_images:
                empty_image = self._create_empty_image()
                if empty_image is None:
                    import torch
                    empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                return (empty_image, "æ²¡æœ‰è¾“å…¥å›¾åƒ")

            # Seedream4.0 ä¸“ç”¨ï¼šå¤šå›¾å‚è€ƒï¼ˆæœ€å¤š6å¼ ï¼‰
            is_seedream = model in ("doubao-seedream-4-0-250828", "seedream-4.0", "doubao-seedream-4-0")
            images_field = []
            if is_seedream:
                # å°†æ‰€æœ‰è¾“å…¥å›¾ç‰‡è½¬ä¸º data URLï¼Œæˆ–è‹¥æœªæ¥æ”¯æŒå­—ç¬¦ä¸²URLè¾“å…¥åˆ™ç›´æ¥é€ä¼ 
                for i, img in enumerate(input_images[:6]):
                    try:
                        if hasattr(img, "cpu") or hasattr(img, "save"):
                            pil_img = self._convert_to_pil(img)
                            buf = BytesIO()
                            pil_img.save(buf, format="PNG")
                            buf.seek(0)
                            import base64
                            b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
                            images_field.append(f"data:image/png;base64,{b64}")
                            print(f"[OpenAIImageAPI] å‚è€ƒå›¾{i+1}è½¬base64æˆåŠŸ: å°ºå¯¸={pil_img.size}")
                        elif isinstance(img, str) and (img.startswith("http://") or img.startswith("https://") or img.startswith("data:image/")):
                            images_field.append(img)
                            print(f"[OpenAIImageAPI] å‚è€ƒå›¾{i+1}ä¸ºURL/æ•°æ®URLï¼Œå·²ç›´æ¥ä½¿ç”¨")
                        else:
                            print(f"[OpenAIImageAPI] å‚è€ƒå›¾{i+1}æ ¼å¼ä¸æ”¯æŒï¼Œè·³è¿‡")
                    except Exception as e:
                        print(f"[OpenAIImageAPI] å‚è€ƒå›¾{i+1}å¤„ç†å¤±è´¥: {e}")
                        continue

                max_images = max(1, min(10, len(images_field)))  # ç”Ÿæˆå¼ æ•°é»˜è®¤ä¸è¾“å…¥æ•°ä¸å¼ºç»‘å®šï¼Œè¿™é‡Œä¸å¼ºåˆ¶=è¾“å…¥æ•°
                payload = {
                    "model": model,
                    "prompt": user_prompt,
                    "image": images_field,  # å¤šå›¾å‚è€ƒ
                    "sequential_image_generation": "auto",
                    "sequential_image_generation_options": {"max_images": max_images},
                    "size": size,  # ç¤ºä¾‹ä½¿ç”¨åƒç´ å°ºå¯¸
                    "stream": False,
                    "response_format": "url",
                    "watermark": False  # æŒ‰ç¤ºä¾‹
                }
            else:
                # é Seedream4.0ï¼šå…¼å®¹æ—§çš„å•å›¾æ¨¡å¼ï¼ˆä¿ç•™åŸæœ‰ adaptive ä¸å›ºå®šå‚æ•°ï¼‰
                try:
                    pil_image = self._convert_to_pil(input_images[0])
                    img_buffer = BytesIO()
                    pil_image.save(img_buffer, format="PNG")
                    img_buffer.seek(0)
                    import base64
                    image_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
                    payload = {
                        "model": model,
                        "prompt": user_prompt,
                        "image": f"data:image/png;base64,{image_base64}",
                        "response_format": "url",
                        "size": "adaptive",
                        "guidance_scale": 5.5,
                        "watermark": False
                    }
                except Exception as e:
                    empty_image = self._create_empty_image()
                    if empty_image is None:
                        import torch
                        empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                    return (empty_image, f"å›¾åƒå¤„ç†å¤±è´¥: {e}")

            print(f"[OpenAIImageAPI] è¯·æ±‚è½½è·: {self._safe_json_dumps(payload)}")
            resp = requests.post(api_url, headers=headers, json=payload, timeout=300)
            print(f"[OpenAIImageAPI] å“åº”çŠ¶æ€ç : {resp.status_code}")
            # è§£æå¤šå›¾å“åº”ç”± _parse_image_response ç»Ÿä¸€å¤„ç†
            return self._parse_image_response(resp)
        except Exception as e:
            empty_image = self._create_empty_image()
            if empty_image is None:
                import torch
                empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
            return (empty_image, f"ç«å±±æ–¹èˆŸå›¾åƒç¼–è¾‘å¤±è´¥: {e}")

    def _edit_images_standard(self, base_url, model, api_key, user_prompt, input_images, size):
        """
        æ ‡å‡†å›¾åƒç¼–è¾‘æ¨¡å¼ï¼ˆå…¶ä»–å¹³å°ï¼‰
        """
        try:
            # æ„é€ multipart/form-dataè¯·æ±‚
            headers = self._build_headers(api_key)
            # ç§»é™¤Content-Typeï¼Œè®©requestsè‡ªåŠ¨è®¾ç½®multipartè¾¹ç•Œ
            headers.pop("Content-Type", None)
            
            api_url = f"{base_url.rstrip('/')}/images/edits"
            print(f"[OpenAIImageAPI] æ­£åœ¨è¯·æ±‚å›¾åƒç¼–è¾‘API: {api_url}")
            print(f"[OpenAIImageAPI] è¯·æ±‚å‚æ•°: model={model}, è¾“å…¥å›¾åƒæ•°é‡={len(input_images)}")
            print(f"[OpenAIImageAPI] è¯·æ±‚å¤´: {headers}")
            
            # å‡†å¤‡multipartæ•°æ®
            files = []
            data = {
                "model": model,
                "prompt": user_prompt,
                "n": "1",
                "size": size,
                "quality": "auto"
            }
            
            print(f"[OpenAIImageAPI] è¯·æ±‚æ•°æ®: {self._safe_json_dumps(data)}")
            print(f"[OpenAIImageAPI] å›¾åƒæ–‡ä»¶æ•°é‡: {len(files)}")

            
            # æ·»åŠ å›¾åƒæ–‡ä»¶
            for i, img in enumerate(input_images):
                try:
                    # å°†å›¾åƒè½¬æ¢ä¸ºPIL Imageå¹¶ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
                    pil_image = self._convert_to_pil(img)
                    img_buffer = BytesIO()
                    pil_image.save(img_buffer, format="PNG")
                    img_buffer.seek(0)
                    
                    # OpenAIå›¾ç”Ÿå›¾æ”¯æŒå¤šå¼ è¾“å…¥å›¾åƒï¼Œæ·»åŠ æ‰€æœ‰å›¾åƒ
                    files.append(("image", (f"image_{i+1}.png", img_buffer.getvalue(), "image/png")))
                    print(f"[OpenAIImageAPI] å›¾åƒ{i+1}å¤„ç†æˆåŠŸ: å°ºå¯¸={pil_image.size}, å¤§å°={len(img_buffer.getvalue())} bytes")
                except Exception as e:
                    empty_image = self._create_empty_image()
                    if empty_image is None:
                        import torch
                        empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                    return (empty_image, f"å›¾åƒ{i+1}å¤„ç†å¤±è´¥: {e}")
            
            # å‘é€multipartè¯·æ±‚
            resp = requests.post(api_url, headers=headers, data=data, files=files, timeout=300)
            
            # ä¸ç«‹å³æŠ›å‡ºå¼‚å¸¸ï¼Œè®©_parse_image_responseå¤„ç†æ‰€æœ‰å“åº”
            print(f"[OpenAIImageAPI] å“åº”çŠ¶æ€ç : {resp.status_code}")
            print(f"[OpenAIImageAPI] å“åº”å¤´: {dict(resp.headers)}")
            
            return self._parse_image_response(resp)
                
        except Exception as e:
            empty_image = self._create_empty_image()
            if empty_image is None:
                import torch
                empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
            return (empty_image, f"å›¾åƒç¼–è¾‘å¤±è´¥: {e}")

    def _parse_image_response(self, resp):
        """
        è§£æå›¾åƒAPIå“åº”
        """
        try:
            # æ£€æŸ¥HTTPçŠ¶æ€ç 
            if resp.status_code != 200:
                error_text = resp.text
                print(f"[OpenAIImageAPI] APIè¿”å›é”™è¯¯çŠ¶æ€ç : {resp.status_code}")
                print(f"[OpenAIImageAPI] é”™è¯¯å“åº”å†…å®¹: {error_text}")
                print(f"[OpenAIImageAPI] å“åº”å¤´: {dict(resp.headers)}")
                # è¿”å›ä¸€ä¸ªç©ºçš„å›¾åƒå¼ é‡è€Œä¸æ˜¯Noneï¼Œé¿å…ComfyUIé”™è¯¯
                empty_image = self._create_empty_image()
                if empty_image is None:
                    # å¦‚æœåˆ›å»ºç©ºå›¾åƒå¤±è´¥ï¼Œä½¿ç”¨æœ€åçš„å¤‡é€‰æ–¹æ¡ˆ
                    import torch
                    empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                return (empty_image, f"APIé”™è¯¯ (çŠ¶æ€ç : {resp.status_code}): {error_text}")
            
            # æ£€æŸ¥å“åº”å†…å®¹æ˜¯å¦ä¸ºç©º
            if not resp.text.strip():
                empty_image = self._create_empty_image()
                if empty_image is None:
                    import torch
                    empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                return (empty_image, "APIè¿”å›ç©ºå“åº”")
            
            # å°è¯•è§£æJSON
            try:
                data = resp.json()
            except json.JSONDecodeError as json_error:
                print(f"[OpenAIImageAPI] JSONè§£æå¤±è´¥: {json_error}")
                print(f"[OpenAIImageAPI] å“åº”å†…å®¹: {resp.text[:500]}...")
                print(f"[OpenAIImageAPI] å“åº”ç±»å‹: {resp.headers.get('content-type', 'unknown')}")
                empty_image = self._create_empty_image()
                if empty_image is None:
                    import torch
                    empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                return (empty_image, f"APIå“åº”æ ¼å¼é”™è¯¯: {resp.text[:200]}")
            
            print(f"[OpenAIImageAPI] APIåŸå§‹å“åº”: {self._safe_json_dumps(data)}")  # è°ƒè¯•è¾“å‡ºï¼Œæˆªæ–­é•¿base64å­—ç¬¦ä¸²
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
            if "error" in data:
                error_info = data["error"]
                error_message = error_info.get("message", "æœªçŸ¥é”™è¯¯")
                error_type = error_info.get("type", "æœªçŸ¥ç±»å‹")
                empty_image = self._create_empty_image()
                if empty_image is None:
                    import torch
                    empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                return (empty_image, f"APIé”™è¯¯ ({error_type}): {error_message}")
            
            # åˆå§‹åŒ–å˜é‡
            pil_image = None
            image_url = None
            
            # è§£æå“åº”æ•°æ® - æ”¯æŒå¤šç§APIæ ¼å¼
            if "data" in data and data["data"]:
                # æ ‡å‡†å›¾åƒç”ŸæˆAPIæ ¼å¼ï¼Œæ”¯æŒå¤šå›¾
                data_list = data["data"]
                print(f"[OpenAIImageAPI] dataæ•°ç»„é•¿åº¦: {len(data_list)}")
                pil_images = []
                image_urls = []
                for idx, image_data in enumerate(data_list):
                    try:
                        print(f"[OpenAIImageAPI] å¤„ç†ç¬¬{idx+1}å¼ : å¯ç”¨å­—æ®µ {list(image_data.keys())}")
                        if "b64_json" in image_data:
                            b64_data = image_data["b64_json"]
                            if isinstance(b64_data, str) and b64_data.startswith('data:image/'):
                                b64_data = b64_data.split(',', 1)[1]
                            image_bytes = base64.b64decode(b64_data)
                            pil = Image.open(BytesIO(image_bytes))
                            pil_images.append(pil)
                            image_urls.append("inline_base64")
                            print(f"[OpenAIImageAPI] ç¬¬{idx+1}å¼ base64è§£ææˆåŠŸ: å°ºå¯¸={pil.size}")
                        elif "url" in image_data:
                            url = image_data["url"]
                            image_urls.append(url)
                            print(f"[OpenAIImageAPI] ä¸‹è½½ç¬¬{idx+1}å¼ : {url}")
                            img_resp = requests.get(url, timeout=30)
                            img_resp.raise_for_status()
                            pil = Image.open(BytesIO(img_resp.content))
                            pil_images.append(pil)
                            print(f"[OpenAIImageAPI] ç¬¬{idx+1}å¼ URLä¸‹è½½æˆåŠŸ: å°ºå¯¸={pil.size}, å¤§å°={len(img_resp.content)} bytes")
                        else:
                            print(f"[OpenAIImageAPI] ç¬¬{idx+1}å¼ æœªæ‰¾åˆ°æ”¯æŒçš„å›¾åƒå­—æ®µï¼Œè·³è¿‡")
                    except Exception as e:
                        print(f"[OpenAIImageAPI] ç¬¬{idx+1}å¼ å¤„ç†å¤±è´¥: {e}")
                        continue
                if not pil_images:
                    empty_image = self._create_empty_image()
                    if empty_image is None:
                        import torch
                        empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                    return (empty_image, "APIå“åº”ä¸­æœªæˆåŠŸè§£æä»»ä½•å›¾åƒ")
                # ç»„æ‰¹ï¼šå°†å¤šå¼ PILè½¬æ¢ä¸ºComfyUIæ‰¹é‡( N,H,W,3 )
                comfyui_batch = self._pil_list_to_comfyui_batch(pil_images)
                # ç”Ÿæˆä¿¡æ¯ï¼šå¤šURLæ¢è¡Œæ‹¼æ¥
                generation_info = self._format_generation_info(data, "\n".join([u for u in image_urls if u]))
                return (comfyui_batch, generation_info)
            elif "images" in data and data["images"]:
                # é­”æ­å¹³å°APIæ ¼å¼
                image_data = data["images"][0]  # å–ç¬¬ä¸€å¼ å›¾åƒ
                print(f"[OpenAIImageAPI] æ‰¾åˆ°é­”æ­å¹³å°å›¾åƒæ•°æ®: {list(image_data.keys())}")
                
                if "url" in image_data:
                    # å¤„ç†URLæ ¼å¼
                    image_url = image_data["url"]
                    print(f"[OpenAIImageAPI] ä¸‹è½½é­”æ­å¹³å°å›¾åƒ: {image_url}")
                    img_resp = requests.get(image_url, timeout=30)
                    img_resp.raise_for_status()
                    pil_image = Image.open(BytesIO(img_resp.content))
                    print(f"[OpenAIImageAPI] é­”æ­å¹³å°å›¾åƒä¸‹è½½æˆåŠŸ: å°ºå¯¸={pil_image.size}, æ¨¡å¼={pil_image.mode}, å¤§å°={len(img_resp.content)} bytes")
                else:
                    print(f"[OpenAIImageAPI] æœªæ‰¾åˆ°æ”¯æŒçš„é­”æ­å¹³å°å›¾åƒæ ¼å¼ï¼Œå¯ç”¨å­—æ®µ: {list(image_data.keys())}")
                    empty_image = self._create_empty_image()
                    if empty_image is None:
                        import torch
                        empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                    return (empty_image, "é­”æ­å¹³å°APIå“åº”ä¸­æœªæ‰¾åˆ°å›¾åƒæ•°æ®")
            elif "data" in data and isinstance(data["data"], list) and len(data["data"]) > 0:
                # SiliconFlowå¹³å°APIæ ¼å¼ - å¯èƒ½ç›´æ¥è¿”å›å›¾åƒæ•°æ®
                image_data = data["data"][0]  # å–ç¬¬ä¸€å¼ å›¾åƒ
                print(f"[OpenAIImageAPI] æ‰¾åˆ°SiliconFlowå›¾åƒæ•°æ®: {list(image_data.keys())}")
                
                if "url" in image_data:
                    # å¤„ç†URLæ ¼å¼
                    image_url = image_data["url"]
                    print(f"[OpenAIImageAPI] ä¸‹è½½SiliconFlowå›¾åƒ: {image_url}")
                    img_resp = requests.get(image_url, timeout=30)
                    img_resp.raise_for_status()
                    pil_image = Image.open(BytesIO(img_resp.content))
                    print(f"[OpenAIImageAPI] SiliconFlowå›¾åƒä¸‹è½½æˆåŠŸ: å°ºå¯¸={pil_image.size}, æ¨¡å¼={pil_image.mode}, å¤§å°={len(img_resp.content)} bytes")
                elif "b64_json" in image_data:
                    # å¤„ç†base64æ ¼å¼
                    b64_data = image_data["b64_json"]
                    print(f"[OpenAIImageAPI] å¤„ç†SiliconFlow base64å›¾åƒæ•°æ®ï¼Œé•¿åº¦: {len(b64_data)}, é¢„è§ˆ: {self._truncate_base64_log(b64_data)}")
                    image_bytes = base64.b64decode(b64_data)
                    pil_image = Image.open(BytesIO(image_bytes))
                    print(f"[OpenAIImageAPI] SiliconFlow base64å›¾åƒåŠ è½½æˆåŠŸ: å°ºå¯¸={pil_image.size}, æ¨¡å¼={pil_image.mode}")
                else:
                    print(f"[OpenAIImageAPI] æœªæ‰¾åˆ°æ”¯æŒçš„SiliconFlowå›¾åƒæ ¼å¼ï¼Œå¯ç”¨å­—æ®µ: {list(image_data.keys())}")
                    empty_image = self._create_empty_image()
                    if empty_image is None:
                        import torch
                        empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                    return (empty_image, "SiliconFlow APIå“åº”ä¸­æœªæ‰¾åˆ°å›¾åƒæ•°æ®")
            elif "choices" in data and data["choices"]:
                # èŠå¤©å®ŒæˆAPIæ ¼å¼ï¼ˆå¦‚fuio.techï¼‰
                choice = data["choices"][0]
                message = choice.get("message", {})
                content = message.get("content", "")
                finish_reason = choice.get("finish_reason", "")
                
                print(f"[OpenAIImageAPI] èŠå¤©å®Œæˆæ ¼å¼å“åº”: finish_reason={finish_reason}")
                print(f"[OpenAIImageAPI] å“åº”å†…å®¹: {content[:200]}...")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¤„ç†ä¸­çš„çŠ¶æ€
                if finish_reason == "processing" or "æ­£åœ¨å‡†å¤‡ç”Ÿæˆä»»åŠ¡" in content:
                    # å¯¹äºå¼‚æ­¥APIï¼Œæˆ‘ä»¬éœ€è¦è½®è¯¢ç­‰å¾…ç»“æœ
                    return self._handle_async_response(data, resp.request.headers, resp.url)
                
                # å°è¯•ä»å†…å®¹ä¸­æå–å›¾åƒURLæˆ–base64
                # è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“APIçš„å“åº”æ ¼å¼æ¥è§£æ
                # æš‚æ—¶è¿”å›å¤„ç†ä¸­çŠ¶æ€
                empty_image = self._create_empty_image()
                if empty_image is None:
                    import torch
                    empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                return (empty_image, f"APIè¿”å›èŠå¤©æ ¼å¼ï¼Œéœ€è¦è¿›ä¸€æ­¥å¤„ç†: {content[:100]}...")
            else:
                print(f"[OpenAIImageAPI] æœªæ‰¾åˆ°æ”¯æŒçš„å“åº”æ ¼å¼ï¼Œå¯ç”¨å­—æ®µ: {list(data.keys())}")
                empty_image = self._create_empty_image()
                if empty_image is None:
                    import torch
                    empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                return (empty_image, "APIå“åº”æ ¼å¼ä¸æ”¯æŒ")
            
            # å¦‚æœåˆ°è¾¾è¿™é‡Œï¼ˆå•å›¾è·¯å¾„ï¼‰ï¼Œè½¬æ¢ä¸ºComfyUIæ ¼å¼
            print(f"[OpenAIImageAPI] å¼€å§‹è½¬æ¢ä¸ºComfyUIæ ¼å¼(å•å›¾)...")
            comfyui_image = self._pil_to_comfyui(pil_image)
            if comfyui_image is None:
                print(f"[OpenAIImageAPI] ComfyUIæ ¼å¼è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨ç©ºå›¾åƒ")
                import torch
                comfyui_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
            else:
                print(f"[OpenAIImageAPI] ComfyUIæ ¼å¼è½¬æ¢æˆåŠŸ: å½¢çŠ¶={comfyui_image.shape}, ç±»å‹={comfyui_image.dtype}")
            generation_info = self._format_generation_info(data, image_url)
            print(f"[OpenAIImageAPI] ç”Ÿæˆä¿¡æ¯: {generation_info}")
            return (comfyui_image, generation_info)
                
        except Exception as e:
            print(f"[OpenAIImageAPI] å“åº”è§£æå¼‚å¸¸: {e}")
            print(f"[OpenAIImageAPI] å“åº”çŠ¶æ€ç : {resp.status_code}")
            print(f"[OpenAIImageAPI] å“åº”å¤´: {dict(resp.headers)}")
            print(f"[OpenAIImageAPI] å“åº”å†…å®¹: {resp.text[:500]}...")
            empty_image = self._create_empty_image()
            if empty_image is None:
                import torch
                empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
            return (empty_image, f"å“åº”è§£æå¤±è´¥: {e}")

    def _parse_chat_completions_response(self, resp):
        """
        è§£æchat/completionsæ ¼å¼çš„APIå“åº”
        ç”¨äºå¤„ç†å¹³å°è¿”å›çš„èŠå¤©æ ¼å¼å“åº”
        """
        try:
            # æ£€æŸ¥HTTPçŠ¶æ€ç 
            if resp.status_code != 200:
                error_text = resp.text
                print(f"[OpenAIImageAPI] Chat Completions APIè¿”å›é”™è¯¯çŠ¶æ€ç : {resp.status_code}")
                print(f"[OpenAIImageAPI] é”™è¯¯å“åº”å†…å®¹: {error_text}")
                empty_image = self._create_empty_image()
                if empty_image is None:
                    import torch
                    empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                return (empty_image, f"Chat Completions APIé”™è¯¯ (çŠ¶æ€ç : {resp.status_code}): {error_text}")
            
            # æ£€æŸ¥å“åº”å†…å®¹æ˜¯å¦ä¸ºç©º
            if not resp.text.strip():
                empty_image = self._create_empty_image()
                if empty_image is None:
                    import torch
                    empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                return (empty_image, "Chat Completions APIè¿”å›ç©ºå“åº”")
            
            # å°è¯•è§£æJSON
            try:
                data = resp.json()
            except json.JSONDecodeError as json_error:
                # å°è¯•è§£æ OpenRouter çš„æµå¼ SSE æ–‡æœ¬ï¼šé€è¡Œè¯»å– "data: {...}" å—å¹¶æ”¶é›† delta.images
                print(f"[OpenAIImageAPI] Chat Completions JSONè§£æå¤±è´¥ï¼Œå°è¯•æŒ‰SSEæµå¼è§£æ: {json_error}")
                text = resp.text or ""
                data_urls = []
                last_chunk = None
                for raw_line in text.splitlines():
                    line = raw_line.strip()
                    if not line.startswith("data:"):
                        continue
                    payload = line[5:].strip()
                    if not payload or payload == "[DONE]":
                        continue
                    try:
                        chunk = json.loads(payload)
                        last_chunk = chunk
                    except Exception as e:
                        continue
                    choices = chunk.get("choices") or []
                    for ch in choices:
                        delta = ch.get("delta") or {}
                        images = delta.get("images") or []
                        if isinstance(images, list):
                            for img_entry in images:
                                url = None
                                if isinstance(img_entry, dict):
                                    if img_entry.get("image_url"):
                                        iu = img_entry.get("image_url")
                                        if isinstance(iu, dict):
                                            url = iu.get("url") or iu.get("data")
                                        elif isinstance(iu, str):
                                            url = iu
                                    url = url or img_entry.get("url") or img_entry.get("data") or img_entry.get("b64_json") or img_entry.get("base64")
                                if isinstance(url, str) and url.startswith("data:image/") and ";base64," in url:
                                    data_urls.append(url)
                if data_urls:
                    try:
                        full_data_url = data_urls[0]
                        b64_part = full_data_url.split(",", 1)[1]
                        image_bytes = base64.b64decode(b64_part)
                        pil_image = Image.open(BytesIO(image_bytes))
                        comfyui_image = self._pil_to_comfyui(pil_image)
                        if comfyui_image is None:
                            import torch
                            comfyui_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                        # æ„é€ æœ€å°ç”Ÿæˆä¿¡æ¯ï¼ˆæ— å®Œæ•´JSONæ—¶ï¼‰
                        minimal_info = last_chunk if isinstance(last_chunk, dict) else {"object": "chat.completion.chunk"}
                        generation_info = self._format_generation_info(minimal_info, "inline_base64")
                        print(f"[OpenAIImageAPI] SSEæµå¼è§£æåˆ°å›¾ç‰‡å¹¶è½¬æ¢æˆåŠŸ: å°ºå¯¸={pil_image.size}")
                        return (comfyui_image, generation_info)
                    except Exception as e:
                        print(f"[OpenAIImageAPI] SSEæµå¼å›¾ç‰‡è§£æå¤±è´¥: {e}")
                # è‹¥SSEä¹Ÿæœªè§£æå‡ºå›¾ç‰‡ï¼ŒæŒ‰åŸè¡Œä¸ºè¿”å›æ ¼å¼é”™è¯¯
                print(f"[OpenAIImageAPI] SSEæµå¼è§£ææœªå‘ç°å›¾ç‰‡ï¼Œè¿”å›æ ¼å¼é”™è¯¯ã€‚")
                empty_image = self._create_empty_image()
                if empty_image is None:
                    import torch
                    empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                return (empty_image, f"Chat Completions APIå“åº”æ ¼å¼é”™è¯¯: {resp.text[:200]}")
            
            print(f"[OpenAIImageAPI] Chat Completions APIåŸå§‹å“åº”: {self._safe_json_dumps(data)}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
            if "error" in data:
                error_info = data["error"]
                error_message = error_info.get("message", "æœªçŸ¥é”™è¯¯")
                error_type = error_info.get("type", "æœªçŸ¥ç±»å‹")
                empty_image = self._create_empty_image()
                if empty_image is None:
                    import torch
                    empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                return (empty_image, f"Chat Completions APIé”™è¯¯ ({error_type}): {error_message}")
            
            # è§£æchoicesæ•°æ®ï¼ˆæ ‡å‡†chat/completionsæ ¼å¼ï¼‰
            if "choices" in data and data["choices"]:
                choice = data["choices"][0]
                message = choice.get("message", {})
                
                # æ£€æŸ¥æ˜¯å¦æœ‰attachmentså­—æ®µï¼ˆç”Ÿæˆçš„å›¾åƒï¼‰
                attachments = message.get("attachments") or message.get("experimental_attachments")
                
                if attachments and len(attachments) > 0:
                    # ä¼˜å…ˆå°è¯•å¤„ç†æ¯ä¸ªé™„ä»¶ä¸­çš„ url æˆ– base64 å­—æ®µ
                    try:
                        att = attachments[0]
                        image_url = att.get("url")
                        if image_url:
                            print(f"[OpenAIImageAPI] ä»Chat Completionså“åº”ä¸­æ‰¾åˆ°å›¾åƒURL: {image_url}")
                            img_resp = requests.get(image_url, timeout=30)
                            img_resp.raise_for_status()
                            pil_image = Image.open(BytesIO(img_resp.content))
                            print(f"[OpenAIImageAPI] Chat Completionså›¾åƒä¸‹è½½æˆåŠŸ: å°ºå¯¸={pil_image.size}, æ¨¡å¼={pil_image.mode}")
                        else:
                            # å¸¸è§base64å­—æ®µåé€‚é…
                            b64_data = att.get("b64_json") or att.get("base64") or att.get("image_base64") or att.get("data") or att.get("content")
                            if isinstance(b64_data, dict):
                                # å…¼å®¹ç»“æ„åŒ–å­—æ®µï¼Œå¦‚ {"data":"data:image/png;base64,..."}
                                b64_data = b64_data.get("data") or b64_data.get("b64_json") or b64_data.get("base64")
                            if b64_data:
                                print(f"[OpenAIImageAPI] ä»attachmentsä¸­å‘ç°base64æ•°æ®ï¼Œé•¿åº¦: {len(str(b64_data))}")
                                if isinstance(b64_data, str) and b64_data.startswith('data:image/'):
                                    b64_data = b64_data.split(',', 1)[1]
                                image_bytes = base64.b64decode(b64_data)
                                pil_image = Image.open(BytesIO(image_bytes))
                                image_url = "inline_base64"
                                print(f"[OpenAIImageAPI] attachments base64å›¾åƒè§£ææˆåŠŸ: å°ºå¯¸={pil_image.size}, æ¨¡å¼={pil_image.mode}")
                            else:
                                raise ValueError("attachmentsä¸­æœªæ‰¾åˆ°urlæˆ–base64å­—æ®µ")

                        # è½¬æ¢ä¸ºComfyUIæ ¼å¼
                        comfyui_image = self._pil_to_comfyui(pil_image)
                        if comfyui_image is None:
                            print(f"[OpenAIImageAPI] ComfyUIæ ¼å¼è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨ç©ºå›¾åƒ")
                            import torch
                            comfyui_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                        else:
                            print(f"[OpenAIImageAPI] Chat Completions ComfyUIæ ¼å¼è½¬æ¢æˆåŠŸ: å½¢çŠ¶={comfyui_image.shape}")
                        
                        # æ ¼å¼åŒ–ç”Ÿæˆä¿¡æ¯
                        generation_info = self._format_generation_info(data, image_url)
                        print(f"[OpenAIImageAPI] Chat Completionsç”Ÿæˆä¿¡æ¯: {generation_info}")
                        
                        return (comfyui_image, generation_info)
                    except Exception as e:
                        print(f"[OpenAIImageAPI] å¤„ç†attachmentsä¸­çš„å›¾åƒæ•°æ®å¤±è´¥: {e}")
                        empty_image = self._create_empty_image()
                        if empty_image is None:
                            import torch
                            empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                        return (empty_image, f"Chat Completionsé™„ä»¶å›¾åƒè§£æå¤±è´¥: {e}")
                else:
                    # ä¼˜å…ˆå°è¯•è§£æ message.imagesï¼ˆå¦‚ OpenRouter Gemini è¿”å›ï¼‰
                    images_list = message.get("images") or []
                    if isinstance(images_list, list) and len(images_list) > 0:
                        try:
                            img_entry = images_list[0]
                            url_or_data = None
                            if isinstance(img_entry, dict):
                                if img_entry.get("image_url"):
                                    iu = img_entry.get("image_url")
                                    if isinstance(iu, dict) and iu.get("url"):
                                        url_or_data = iu.get("url")
                                    else:
                                        url_or_data = iu
                                if not url_or_data:
                                    url_or_data = img_entry.get("url") or img_entry.get("data") or img_entry.get("b64_json") or img_entry.get("base64")

                            if not url_or_data:
                                raise ValueError("images[0] æœªåŒ…å«å¯è¯†åˆ«çš„urlæˆ–base64å­—æ®µ")

                            if isinstance(url_or_data, str) and url_or_data.startswith("http"):
                                img_resp = requests.get(url_or_data, timeout=30)
                                img_resp.raise_for_status()
                                pil_image = Image.open(BytesIO(img_resp.content))
                                image_url = url_or_data
                            else:
                                b64_data = url_or_data
                                if isinstance(b64_data, dict):
                                    b64_data = b64_data.get("data") or b64_data.get("b64_json") or b64_data.get("base64")
                                if not isinstance(b64_data, str):
                                    raise ValueError("images[0] base64å­—æ®µä¸æ˜¯å­—ç¬¦ä¸²")
                                if b64_data.startswith('data:image/'):
                                    b64_data = b64_data.split(',', 1)[1]
                                image_bytes = base64.b64decode(b64_data)
                                pil_image = Image.open(BytesIO(image_bytes))
                                image_url = "inline_base64"

                            comfyui_image = self._pil_to_comfyui(pil_image)
                            if comfyui_image is None:
                                import torch
                                comfyui_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                            generation_info = self._format_generation_info(data, image_url)
                            return (comfyui_image, generation_info)
                        except Exception as e:
                            print(f"[OpenAIImageAPI] è§£æmessage.imageså¤±è´¥: {e}")
                            # ä¸ä¸­æ–­ï¼Œç»§ç»­å°è¯•ä»contentä¸­æå–

                    # æ£€æŸ¥æ¶ˆæ¯å†…å®¹æ˜¯å¦åŒ…å«å›¾åƒä¿¡æ¯
                    content = message.get("content", "")
                    print(f"[OpenAIImageAPI] Chat Completionsæ¶ˆæ¯å†…å®¹: {content[:200]}...")
                    
                    # content å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–ç»“æ„åŒ–æ•°ç»„ï¼Œå…ˆåšç»“æ„åŒ–å…¼å®¹
                    if isinstance(content, list):
                        # å…¼å®¹ openai æ ¼å¼ [{type: image_url, image_url: {url: ...}}, {type: text, text: ...}]
                        for part in content:
                            try:
                                if isinstance(part, dict):
                                    if part.get("type") == "image_url":
                                        iu = part.get("image_url")
                                        u = None
                                        if isinstance(iu, dict):
                                            u = iu.get("url") or iu.get("data")
                                        elif isinstance(iu, str):
                                            u = iu
                                        if u:
                                            print(f"[OpenAIImageAPI] ä»ç»“æ„åŒ–contentä¸­æ‰¾åˆ°URL: {u}")
                                            if isinstance(u, str) and u.startswith('data:image/'):
                                                payload = u.split(',', 1)[1] if ',' in u else u
                                                image_bytes = base64.b64decode(payload)
                                                pil_image = Image.open(BytesIO(image_bytes))
                                                src_hint = "inline_base64"
                                            else:
                                                img_resp = requests.get(u, timeout=30)
                                                img_resp.raise_for_status()
                                                pil_image = Image.open(BytesIO(img_resp.content))
                                                src_hint = u
                                            comfyui_image = self._pil_to_comfyui(pil_image)
                                            if comfyui_image is None:
                                                import torch
                                                comfyui_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                                            generation_info = self._format_generation_info(data, src_hint)
                                            return (comfyui_image, generation_info)
                                    # å¯èƒ½è¿”å› base64 data url
                                    if part.get("type") in ("image", "image_base64"):
                                        b64_data = part.get("data") or part.get("base64") or part.get("b64_json")
                                        if isinstance(b64_data, str):
                                            if b64_data.startswith('data:image/'):
                                                payload = b64_data.split(',', 1)[1]
                                            else:
                                                payload = b64_data
                                            image_bytes = base64.b64decode(payload)
                                            pil_image = Image.open(BytesIO(image_bytes))
                                            comfyui_image = self._pil_to_comfyui(pil_image)
                                            if comfyui_image is None:
                                                import torch
                                                comfyui_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                                            generation_info = self._format_generation_info(data, "inline_base64")
                                            return (comfyui_image, generation_info)
                            except Exception as e:
                                print(f"[OpenAIImageAPI] è§£æç»“æ„åŒ–contentå¤±è´¥ï¼Œè·³è¿‡è¯¥éƒ¨åˆ†: {e}")
                        # è‹¥ç»“æ„åŒ–æœªå‘½ä¸­ï¼Œç»§ç»­æŒ‰å­—ç¬¦ä¸²æ–¹å¼å°è¯•
                        content = json.dumps(content, ensure_ascii=False)

                    # å°è¯•ä»å†…å®¹ä¸­æå–å›¾åƒURLï¼ˆæŸäº›å¹³å°å¯èƒ½åœ¨æ–‡æœ¬ä¸­è¿”å›URLï¼‰
                    # é¦–å…ˆå°è¯•æå–Markdownæ ¼å¼çš„å›¾åƒé“¾æ¥ ![alt](url)
                    markdown_pattern = r'!\[.*?\]\((https?://[^)]+\.(?:jpg|jpeg|png|gif|webp|bmp)[^)]*)\)'
                    markdown_urls = re.findall(markdown_pattern, content, re.IGNORECASE)
                    print(f"[OpenAIImageAPI] Markdownæ ¼å¼URLæå–ç»“æœ: {markdown_urls}")
                    
                    # å¦‚æœæ²¡æ‰¾åˆ°Markdownæ ¼å¼ï¼Œå°è¯•ç›´æ¥æå–URLï¼ˆæ”¯æŒæŸ¥è¯¢å‚æ•°ï¼‰
                    if not markdown_urls:
                        url_pattern = r'https?://[^\s<>"{}|\\^`\[\]()]+\.(?:jpg|jpeg|png|gif|webp|bmp)(?:\?[^\s<>"{}|\\^`\[\]()]*)?'
                        urls = re.findall(url_pattern, content, re.IGNORECASE)
                        print(f"[OpenAIImageAPI] ç›´æ¥URLæå–ç»“æœ: {urls}")
                    else:
                        urls = markdown_urls
                        print(f"[OpenAIImageAPI] ä½¿ç”¨Markdown URLæå–ç»“æœ")
                    
                    if urls:
                        image_url = urls[0]
                        print(f"[OpenAIImageAPI] ä»Chat Completionsæ–‡æœ¬å†…å®¹ä¸­æå–åˆ°å›¾åƒURL: {image_url}")
                        try:
                            # ä¸‹è½½å›¾åƒ
                            img_resp = requests.get(image_url, timeout=30)
                            img_resp.raise_for_status()
                            pil_image = Image.open(BytesIO(img_resp.content))
                            print(f"[OpenAIImageAPI] æå–URLå›¾åƒä¸‹è½½æˆåŠŸ: å°ºå¯¸={pil_image.size}")
                            
                            # è½¬æ¢ä¸ºComfyUIæ ¼å¼
                            comfyui_image = self._pil_to_comfyui(pil_image)
                            if comfyui_image is None:
                                import torch
                                comfyui_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                            
                            # æ ¼å¼åŒ–ç”Ÿæˆä¿¡æ¯
                            generation_info = self._format_generation_info(data, image_url)
                            
                            return (comfyui_image, generation_info)
                            
                        except Exception as e:
                            print(f"[OpenAIImageAPI] æå–URLå›¾åƒä¸‹è½½å¤±è´¥: {e}")
                            empty_image = self._create_empty_image()
                            if empty_image is None:
                                import torch
                                empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                            return (empty_image, f"æå–URLå›¾åƒä¸‹è½½å¤±è´¥: {e}")
                    else:
                        # å°è¯•åŒ¹é… data URL ä¸­çš„ base64 å›¾ç‰‡
                        dataurl_pattern = r'(data:image\/(?:png|jpeg|jpg|webp|gif|bmp);base64,([A-Za-z0-9+\/=]+))'
                        data_urls = re.findall(dataurl_pattern, content, re.IGNORECASE)
                        if data_urls:
                            try:
                                full_data, b64_part = data_urls[0]
                                print(f"[OpenAIImageAPI] ä»æ–‡æœ¬ä¸­æå–åˆ°data URL base64ï¼Œé•¿åº¦: {len(b64_part)}")
                                image_bytes = base64.b64decode(b64_part)
                                pil_image = Image.open(BytesIO(image_bytes))
                                comfyui_image = self._pil_to_comfyui(pil_image)
                                if comfyui_image is None:
                                    import torch
                                    comfyui_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                                generation_info = self._format_generation_info(data, "inline_base64")
                                return (comfyui_image, generation_info)
                            except Exception as e:
                                print(f"[OpenAIImageAPI] data URL base64è§£æå¤±è´¥: {e}")
                        
                        # å…œåº•ï¼šå°è¯•ä»æ–‡æœ¬ä¸­æå–é•¿base64æ®µå¹¶å°è¯•ä½œä¸ºå›¾ç‰‡è§£ç 
                        try:
                            candidate_pattern = r'([A-Za-z0-9+\/=]{200,})'
                            candidates = re.findall(candidate_pattern, content)
                            print(f"[OpenAIImageAPI] å‘ç°æ½œåœ¨base64æ®µæ•°é‡: {len(candidates)}")
                            for cand in candidates:
                                try:
                                    image_bytes = base64.b64decode(cand)
                                    pil = Image.open(BytesIO(image_bytes))
                                    pil.load()
                                    print(f"[OpenAIImageAPI] çº¯base64å›¾ç‰‡è§£ææˆåŠŸ: å°ºå¯¸={pil.size}, æ¨¡å¼={pil.mode}")
                                    comfyui_image = self._pil_to_comfyui(pil)
                                    if comfyui_image is None:
                                        import torch
                                        comfyui_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                                    generation_info = self._format_generation_info(data, "inline_base64")
                                    return (comfyui_image, generation_info)
                                except Exception:
                                    continue
                        except Exception as e:
                            print(f"[OpenAIImageAPI] çº¯base64å…œåº•è§£æå¤±è´¥: {e}")
                    # è‹¥ä¸Šè¿°å¤šç§æ–¹å¼å‡æœªè§£ææˆåŠŸï¼Œè¿”å›ç©ºå›¾åƒ
                    empty_image = self._create_empty_image()
                    if empty_image is None:
                        import torch
                        empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                    return (empty_image, f"Chat Completionså“åº”ä¸­æœªæ‰¾åˆ°å›¾åƒæ•°æ®: {content[:100]}...")
            else:
                print(f"[OpenAIImageAPI] Chat Completionså“åº”æ ¼å¼å¼‚å¸¸ï¼Œå¯ç”¨å­—æ®µ: {list(data.keys())}")
                empty_image = self._create_empty_image()
                if empty_image is None:
                    import torch
                    empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                return (empty_image, "Chat Completionså“åº”æ ¼å¼ä¸æ”¯æŒ")
                
        except Exception as e:
            print(f"[OpenAIImageAPI] Chat Completionså“åº”è§£æå¼‚å¸¸: {e}")
            print(f"[OpenAIImageAPI] å“åº”çŠ¶æ€ç : {resp.status_code}")
            print(f"[OpenAIImageAPI] å“åº”å†…å®¹: {resp.text[:500]}...")
            empty_image = self._create_empty_image()
            if empty_image is None:
                import torch
                empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
            return (empty_image, f"Chat Completionså“åº”è§£æå¤±è´¥: {e}")

    def _handle_async_response(self, initial_data, headers, api_url):
        """
        å¤„ç†å¼‚æ­¥å“åº”ï¼Œè½®è¯¢ç­‰å¾…ç»“æœ
        """
        import time
        
        # è·å–è¯·æ±‚IDç”¨äºè½®è¯¢
        request_id = initial_data.get("id")
        if not request_id:
            empty_image = self._create_empty_image()
            if empty_image is None:
                import torch
                empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
            return (empty_image, "æ— æ³•è·å–è¯·æ±‚IDè¿›è¡Œè½®è¯¢")
        
        print(f"[OpenAIImageAPI] å¼€å§‹è½®è¯¢ç­‰å¾…ç»“æœï¼Œè¯·æ±‚ID: {request_id}")
        
        # è½®è¯¢å‚æ•°
        max_attempts = 30  # æœ€å¤§è½®è¯¢æ¬¡æ•°
        poll_interval = 10  # è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰
        
        for attempt in range(max_attempts):
            print(f"[OpenAIImageAPI] è½®è¯¢å°è¯• {attempt + 1}/{max_attempts}")
            
            try:
                # æ„é€ è½®è¯¢è¯·æ±‚
                poll_payload = {
                    "id": request_id
                }
                
                # å‘é€è½®è¯¢è¯·æ±‚
                poll_resp = requests.post(
                    api_url,
                    headers=headers,
                    json=poll_payload,
                    timeout=30
                )
                
                if poll_resp.status_code == 200:
                    poll_data = poll_resp.json()
                    print(f"[OpenAIImageAPI] è½®è¯¢å“åº”: {poll_data}")
                    
                    # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                    if "choices" in poll_data and poll_data["choices"]:
                        choice = poll_data["choices"][0]
                        finish_reason = choice.get("finish_reason", "")
                        
                        if finish_reason != "processing":
                            # ä»»åŠ¡å®Œæˆï¼Œè§£æç»“æœ
                            print(f"[OpenAIImageAPI] ä»»åŠ¡å®Œæˆï¼Œfinish_reason: {finish_reason}")
                            return self._parse_image_response(poll_resp)
                        else:
                            print(f"[OpenAIImageAPI] ä»»åŠ¡ä»åœ¨å¤„ç†ä¸­ï¼Œç­‰å¾… {poll_interval} ç§’...")
                            time.sleep(poll_interval)
                    else:
                        print(f"[OpenAIImageAPI] è½®è¯¢å“åº”æ ¼å¼å¼‚å¸¸: {poll_data}")
                        time.sleep(poll_interval)
                else:
                    print(f"[OpenAIImageAPI] è½®è¯¢è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {poll_resp.status_code}")
                    time.sleep(poll_interval)
                    
            except Exception as e:
                print(f"[OpenAIImageAPI] è½®è¯¢å¼‚å¸¸: {e}")
                time.sleep(poll_interval)
        
        # è¶…æ—¶
        empty_image = self._create_empty_image()
        if empty_image is None:
            import torch
            empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
        return (empty_image, f"è½®è¯¢è¶…æ—¶ï¼Œè¯·æ£€æŸ¥åå°ä»»åŠ¡çŠ¶æ€")

    def _poll_modelscope_task(self, base_url, task_id, api_key):
        """
        è½®è¯¢é­”æ­ï¼ˆModelScopeï¼‰å¼‚æ­¥ä»»åŠ¡ï¼Œç›´åˆ°æˆåŠŸæˆ–è¶…æ—¶ã€‚
        æˆåŠŸåä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸º ComfyUI æ ¼å¼ã€‚
        """
        import time
        try:
            tasks_url = f"https://api-inference.modelscope.cn/v1/tasks/{task_id}"
            headers = {
                "Authorization": f"Bearer {api_key}",
                "X-ModelScope-Task-Type": "image_generation"
            }

            max_attempts = 60  # æœ€é•¿çº¦ 5 åˆ†é’Ÿï¼ˆ60*5sï¼‰
            poll_interval = 5

            print(f"[OpenAIImageAPI] å¼€å§‹è½®è¯¢é­”æ­ä»»åŠ¡: task_id={task_id}, url={tasks_url}")
            for attempt in range(max_attempts):
                print(f"[OpenAIImageAPI] é­”æ­è½®è¯¢å°è¯• {attempt + 1}/{max_attempts}")
                resp = requests.get(tasks_url, headers=headers, timeout=60)
                if resp.status_code != 200:
                    print(f"[OpenAIImageAPI] ä»»åŠ¡æŸ¥è¯¢å¤±è´¥: {resp.status_code}, {resp.text[:200]}")
                    time.sleep(poll_interval)
                    continue

                data = resp.json()
                #print(f"[OpenAIImageAPI] ä»»åŠ¡æŸ¥è¯¢è¿”å›: {self._safe_json_dumps(data)}")
                status = data.get("task_status") or data.get("status")

                if status == "SUCCEED":
                    output_images = data.get("output_images") or []
                    if not output_images:
                        # å…¼å®¹å¯èƒ½çš„å­—æ®µ
                        images = data.get("images") or []
                        if images and isinstance(images[0], dict):
                            image_url = images[0].get("url")
                        else:
                            image_url = images[0] if images else None
                    else:
                        image_url = output_images[0]

                    if not image_url:
                        raise Exception("ä»»åŠ¡æˆåŠŸä½†æœªè¿”å›å›¾ç‰‡URL")

                    print(f"[OpenAIImageAPI] ä»»åŠ¡å®Œæˆï¼Œä¸‹è½½å›¾ç‰‡: {image_url}")
                    img_resp = requests.get(image_url, timeout=60)
                    img_resp.raise_for_status()
                    pil_image = Image.open(BytesIO(img_resp.content))
                    if pil_image.mode != "RGB":
                        pil_image = pil_image.convert("RGB")

                    comfyui_image = self._pil_to_comfyui(pil_image)
                    if comfyui_image is None:
                        import torch
                        comfyui_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)

                    # æ„é€ ç”Ÿæˆä¿¡æ¯ï¼Œè‡³å°‘åŒ…å« image_url
                    gen_info = self._format_generation_info({"images": [{"url": image_url}]}, image_url)
                    return (comfyui_image, gen_info)

                if status == "FAILED":
                    raise Exception(f"ä»»åŠ¡å¤±è´¥: {self._safe_json_dumps(data)}")

                # ç»§ç»­ç­‰å¾…
                time.sleep(poll_interval)

            # è¶…æ—¶
            empty_image = self._create_empty_image()
            if empty_image is None:
                import torch
                empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
            return (empty_image, "é­”æ­ä»»åŠ¡è½®è¯¢è¶…æ—¶")

        except Exception as e:
            print(f"[OpenAIImageAPI] é­”æ­ä»»åŠ¡è½®è¯¢å¼‚å¸¸: {e}")
            empty_image = self._create_empty_image()
            if empty_image is None:
                import torch
                empty_image = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
            return (empty_image, f"é­”æ­ä»»åŠ¡è½®è¯¢å¤±è´¥: {e}")

    def _convert_to_pil(self, image):
        """
        å°†ComfyUIçš„IMAGEè½¬æ¢ä¸ºPIL Image
        """
        try:
            print(f"[OpenAIImageAPI] å¼€å§‹è½¬æ¢å›¾åƒï¼Œè¾“å…¥ç±»å‹: {type(image)}")
            
            # ComfyUIçš„IMAGEæ˜¯torch.Tensorï¼Œéœ€è¦è½¬æ¢ä¸ºPIL Image
            if hasattr(image, 'cpu'):  # æ˜¯torch.Tensor
                print(f"[OpenAIImageAPI] æ£€æµ‹åˆ°torch.Tensorï¼Œå½¢çŠ¶: {image.shape}, ç±»å‹: {image.dtype}")
                # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œç„¶åè½¬ä¸ºPIL Image
                import torch
                if image.dim() == 4:  # batchç»´åº¦ï¼Œå–ç¬¬ä¸€å¼ 
                    image = image[0]
                    print(f"[OpenAIImageAPI] å–batchç¬¬ä¸€å¼ ï¼Œæ–°å½¢çŠ¶: {image.shape}")
                # è½¬æ¢ä¸ºnumpyå¹¶è°ƒæ•´é€šé“é¡ºåº (C,H,W) -> (H,W,C)
                image_np = image.cpu().numpy()
                print(f"[OpenAIImageAPI] è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œå½¢çŠ¶: {image_np.shape}, ç±»å‹: {image_np.dtype}")
                if image_np.shape[0] == 3:  # å¦‚æœæ˜¯(C,H,W)æ ¼å¼
                    image_np = image_np.transpose(1, 2, 0)
                    print(f"[OpenAIImageAPI] è°ƒæ•´é€šé“é¡ºåºåï¼Œå½¢çŠ¶: {image_np.shape}")
                # ç¡®ä¿å€¼åœ¨0-255èŒƒå›´å†…
                image_np = (image_np * 255).clip(0, 255).astype('uint8')
                print(f"[OpenAIImageAPI] å½’ä¸€åŒ–åˆ°0-255ï¼Œå€¼èŒƒå›´: {image_np.min()}-{image_np.max()}")
                img = Image.fromarray(image_np)
                print(f"[OpenAIImageAPI] PILå›¾åƒåˆ›å»ºæˆåŠŸ: å°ºå¯¸={img.size}, æ¨¡å¼={img.mode}")
            elif hasattr(image, 'save'):  # å·²ç»æ˜¯PIL Image
                print(f"[OpenAIImageAPI] æ£€æµ‹åˆ°PIL Imageï¼Œå°ºå¯¸={image.size}, æ¨¡å¼={image.mode}")
                img = image
            else:
                # å¦‚æœæ˜¯numpyæ•°ç»„ï¼Œç›´æ¥è½¬æ¢
                import numpy as np
                if isinstance(image, np.ndarray):
                    print(f"[OpenAIImageAPI] æ£€æµ‹åˆ°numpyæ•°ç»„ï¼Œå½¢çŠ¶: {image.shape}, ç±»å‹: {image.dtype}")
                    if image.shape[0] == 3:  # å¦‚æœæ˜¯(C,H,W)æ ¼å¼
                        image = image.transpose(1, 2, 0)
                        print(f"[OpenAIImageAPI] è°ƒæ•´é€šé“é¡ºåºåï¼Œå½¢çŠ¶: {image.shape}")
                    # ç¡®ä¿å€¼åœ¨0-255èŒƒå›´å†…
                    if image.max() <= 1.0:  # å¦‚æœæ˜¯0-1èŒƒå›´
                        image = (image * 255).clip(0, 255).astype('uint8')
                        print(f"[OpenAIImageAPI] å½’ä¸€åŒ–åˆ°0-255ï¼Œå€¼èŒƒå›´: {image.min()}-{image.max()}")
                    img = Image.fromarray(image)
                    print(f"[OpenAIImageAPI] PILå›¾åƒåˆ›å»ºæˆåŠŸ: å°ºå¯¸={img.size}, æ¨¡å¼={img.mode}")
                else:
                    raise Exception(f"ä¸æ”¯æŒçš„å›¾åƒæ ¼å¼: {type(image)}")
            
            return img
            
        except Exception as e:
            print(f"[OpenAIImageAPI] å›¾åƒè½¬æ¢å¤±è´¥: {e}")
            raise Exception(f"å›¾åƒè½¬æ¢å¤±è´¥: {e}")

    def _pil_to_comfyui(self, pil_image):
        """
        å°†PIL Imageè½¬æ¢ä¸ºComfyUIæ ¼å¼
        å‚è€ƒGLMå›¾åƒèŠ‚ç‚¹çš„æ ‡å‡†å¤„ç†æ–¹å¼ï¼Œç¡®ä¿æ ¼å¼ç¬¦åˆComfyUIè¦æ±‚
        """
        try:
            import torch
            import numpy as np
            
            # è½¬æ¢ä¸ºRGBæ¨¡å¼
            if pil_image.mode != "RGB":
                pil_image = pil_image.convert("RGB")
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œç›´æ¥ä½¿ç”¨float32å¹¶å½’ä¸€åŒ–åˆ°0-1
            # å‚è€ƒGLMå›¾åƒèŠ‚ç‚¹çš„å¤„ç†æ–¹å¼
            image_np = np.array(pil_image, dtype=np.float32) / 255.0
            
            # ç¡®ä¿æ•°ç»„å½¢çŠ¶æ­£ç¡® (H, W, 3)
            if len(image_np.shape) != 3 or image_np.shape[2] != 3:
                raise Exception(f"å›¾åƒæ ¼å¼é”™è¯¯: æœŸæœ›(H,W,3)ï¼Œå®é™…{image_np.shape}")
            
            # è½¬æ¢ä¸ºtorch.Tensorï¼Œä¿æŒ (H, W, 3) æ ¼å¼
            image_tensor = torch.from_numpy(image_np)
            
            # ç¡®ä¿tensorå½¢çŠ¶æ­£ç¡® (H, W, 3)
            if image_tensor.shape != (image_np.shape[0], image_np.shape[1], 3):
                raise Exception(f"Tensorå½¢çŠ¶é”™è¯¯: æœŸæœ›(H,W,3)ï¼Œå®é™…{image_tensor.shape}")
            
            # æ·»åŠ batchç»´åº¦ï¼Œæœ€ç»ˆæ ¼å¼ä¸º (1, H, W, 3)
            image_tensor = image_tensor.unsqueeze(0)
            
            # æœ€ç»ˆæ£€æŸ¥
            if image_tensor.shape[0] != 1 or image_tensor.shape[3] != 3:
                raise Exception(f"æœ€ç»ˆtensorå½¢çŠ¶é”™è¯¯: æœŸæœ›(1,H,W,3)ï¼Œå®é™…{image_tensor.shape}")
            
            return image_tensor
            
        except Exception as e:
            print(f"[OpenAIImageAPI] ComfyUIæ ¼å¼è½¬æ¢å¤±è´¥: {e}")
            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªå®‰å…¨çš„ç©ºå›¾åƒ
            try:
                import torch
                # è¿”å›ç¬¦åˆComfyUIæ ¼å¼çš„ç©ºå›¾åƒ (1, H, W, 3)
                return torch.zeros(1, 512, 512, 3, dtype=torch.float32)
            except Exception as e2:
                print(f"[OpenAIImageAPI] åˆ›å»ºå®‰å…¨ç©ºå›¾åƒä¹Ÿå¤±è´¥: {e2}")
                return None

    def _format_generation_info(self, data, image_url):
        """
        æ ¼å¼åŒ–ç”Ÿæˆä¿¡æ¯ï¼ŒåŒ…å«image_urlå’Œtotal_tokens
        """
        generation_info = []
        
        # æ·»åŠ image_urlï¼ˆå¿…é€‰ï¼‰
        if image_url:
            generation_info.append(f"image_url:\n{image_url}")
        
        # æå–total_tokensï¼ˆå¯é€‰ï¼‰
        total_tokens = None
        
        # ä»ä¸åŒä½ç½®å°è¯•æå–total_tokens
        if "usage" in data:
            usage = data["usage"]
            total_tokens = usage.get('total_tokens')
        
        # å¦‚æœusageä¸­æ²¡æœ‰ï¼Œå°è¯•ä»å…¶ä»–ä½ç½®æå–
        if not total_tokens and "total_tokens" in data:
            total_tokens = data["total_tokens"]
        
        if total_tokens is not None:
            generation_info.append(f"total_tokens: {total_tokens}")
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•ä¿¡æ¯ï¼Œè¿”å›é»˜è®¤ä¿¡æ¯
        if not generation_info:
            return "image_url: unknown, total_tokens: unknown"
        
        return "\n\n".join(generation_info)

    def _format_tokens_usage(self, usage):
        """
        å°†tokens_usageæ ¼å¼åŒ–ä¸ºæ˜“è¯»çš„å­—ç¬¦ä¸²
        """
        if not usage:
            return ""
        
        total_tokens = usage.get('total_tokens', '-')
        input_tokens = usage.get('input_tokens', '-')
        output_tokens = usage.get('output_tokens', '-')
        
        # å¤„ç†è¯¦ç»†çš„tokenä¿¡æ¯
        input_details = usage.get('input_tokens_details', {})
        if input_details:
            text_tokens = input_details.get('text_tokens', '-')
            image_tokens = input_details.get('image_tokens', '-')
            return f"total_tokens={total_tokens}, input_tokens={input_tokens}(text:{text_tokens},image:{image_tokens}), output_tokens={output_tokens}"
        
        return f"total_tokens={total_tokens}, input_tokens={input_tokens}, output_tokens={output_tokens}"

    def _create_empty_image(self):
        """
        åˆ›å»ºä¸€ä¸ªç©ºçš„å›¾åƒå¼ é‡ï¼Œç”¨äºé”™è¯¯å¤„ç†
        ç¡®ä¿è¿”å›ç¬¦åˆComfyUIæ ¼å¼çš„å›¾åƒå¼ é‡ (1, H, W, 3)
        """
        try:
            import torch
            import numpy as np
            # åˆ›å»ºä¸€ä¸ªç¬¦åˆComfyUIæ ¼å¼çš„ç©ºå›¾åƒå¼ é‡ (1, H, W, 3)
            # ä½¿ç”¨numpyå…ˆåˆ›å»ºï¼Œç„¶åè½¬æ¢ä¸ºtorch tensorï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
            empty_array = np.zeros((512, 512, 3), dtype=np.float32)
            # è½¬æ¢ä¸ºPIL Imageï¼Œç„¶åä½¿ç”¨_pil_to_comfyuiç¡®ä¿æ ¼å¼ä¸€è‡´
            pil_image = Image.fromarray((empty_array * 255).astype(np.uint8))
            return self._pil_to_comfyui(pil_image)
        except Exception as e:
            print(f"[OpenAIImageAPI] åˆ›å»ºç©ºå›¾åƒå¤±è´¥: {e}")
            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå°è¯•ç›´æ¥åˆ›å»ºtorch tensor
            try:
                import torch
                # è¿”å›ç¬¦åˆComfyUIæ ¼å¼çš„ç©ºå›¾åƒ (1, H, W, 3)
                empty_tensor = torch.zeros(1, 512, 512, 3, dtype=torch.float32)
                return empty_tensor
            except Exception as e2:
                print(f"[OpenAIImageAPI] åˆ›å»ºtorch tensorä¹Ÿå¤±è´¥: {e2}")
                # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼šè¿”å›Noneï¼Œè®©ComfyUIå¤„ç†
                return None

    def _build_headers(self, api_key):
        """
        æ„å»ºè¯·æ±‚å¤´
        """
        return {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

    def _generate_size_from_ratio(self, resolution, ratio):
        """
        æ ¹æ®resolutionä¸ratioä»ratio_map.jsonæ˜ å°„å‡ºå…·ä½“åƒç´ å°ºå¯¸å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚"1104x1472"ã€‚
        """
        try:
            ratio_map = self._load_ratio_map()
            key_map = {
                "1k": "1k_ratios",
                "1.5k": "1.5k_ratios",
                "2k": "2k_ratios",
                "4k": "4k_ratios",
                "gpt4o": "gpt4o_ratios",
            }
            key = key_map.get(resolution)
            if not key or key not in ratio_map:
                raise KeyError(f"ä¸æ”¯æŒçš„resolution: {resolution}")
            level_map = ratio_map[key]
            if ratio not in level_map:
                raise KeyError(f"ä¸æ”¯æŒçš„æ¯”ä¾‹: {ratio}")
            dims = level_map[ratio]
            w = dims.get("width")
            h = dims.get("height")
            if not isinstance(w, int) or not isinstance(h, int):
                raise ValueError(f"æ˜ å°„å€¼éæ³•: {dims}")
            return f"{w}x{h}"
        except Exception as e:
            print(f"[OpenAIImageAPI] æ˜ å°„resolution/ratioå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤1024x1024: {e}")
            return "1024x1024"

    def _truncate_base64_log(self, base64_str, max_length=50):
        """
        æˆªæ–­base64å­—ç¬¦ä¸²ç”¨äºæ—¥å¿—è®°å½•ï¼Œé¿å…åˆ·å±
        """
        if not base64_str:
            return ""
        if len(base64_str) <= max_length:
            return base64_str
        return f"{base64_str[:max_length]}... (æ€»é•¿åº¦: {len(base64_str)})"

    def _pil_list_to_comfyui_batch(self, pil_list):
        """
        å°†å¤šå¼ PILå›¾ç‰‡è½¬æ¢ä¸ºComfyUIæ‰¹é‡å›¾åƒå¼ é‡ï¼Œå½¢çŠ¶ (N, H, W, 3)ã€‚
        è‹¥å°ºå¯¸ä¸åŒï¼ŒæŒ‰ç¬¬ä¸€å¼ å°ºå¯¸å°†å…¶ä½™å›¾ç‰‡ç­‰æ¯”ç¼©æ”¾å¹¶ä¸­å¿ƒå¡«å……åˆ°ç›¸åŒå¤§å°ï¼Œé¿å…ç»´åº¦ä¸ä¸€è‡´ã€‚
        """
        try:
            import torch
            import numpy as np

            if not pil_list:
                return torch.zeros(1, 512, 512, 3, dtype=torch.float32)

            # ç›®æ ‡å°ºå¯¸é‡‡ç”¨é¦–å›¾å°ºå¯¸
            tgt_w, tgt_h = pil_list[0].size
            batch = []
            for i, img in enumerate(pil_list):
                if img.mode != "RGB":
                    img = img.convert("RGB")
                w, h = img.size
                if (w, h) != (tgt_w, tgt_h):
                    # ä¿æŒæ¯”ä¾‹ç¼©æ”¾åˆ°ä¸è¶…è¿‡ç›®æ ‡å°ºå¯¸çš„æœ€å¤§å°ºå¯¸ï¼Œç„¶åå±…ä¸­è´´å›¾
                    img = self._resize_and_pad(img, (tgt_w, tgt_h))
                arr = np.array(img, dtype=np.float32) / 255.0  # (H,W,3)
                batch.append(arr)
            batch_np = np.stack(batch, axis=0)  # (N,H,W,3)
            return torch.from_numpy(batch_np)
        except Exception as e:
            print(f"[OpenAIImageAPI] æ‰¹é‡è½¬æ¢å¤±è´¥: {e}")
            try:
                # é€€åŒ–ä¸ºå•å¼ è½¬æ¢
                return self._pil_to_comfyui(pil_list[0])
            except Exception:
                import torch
                return torch.zeros(1, 512, 512, 3, dtype=torch.float32)

    def _resize_and_pad(self, pil_img, target_size):
        """
        ç­‰æ¯”ç¼©æ”¾å¹¶ç”¨é»‘è¾¹å¡«å……åˆ°ç›®æ ‡å°ºå¯¸ã€‚
        """
        from PIL import Image as _Image
        tgt_w, tgt_h = target_size
        w, h = pil_img.size
        # è®¡ç®—ç­‰æ¯”ç¼©æ”¾
        scale = min(tgt_w / w, tgt_h / h)
        new_w = max(1, int(w * scale))
        new_h = max(1, int(h * scale))
        resized = pil_img.resize((new_w, new_h), _Image.LANCZOS)
        # åˆ›å»ºç”»å¸ƒå¹¶å±…ä¸­ç²˜è´´
        canvas = _Image.new("RGB", (tgt_w, tgt_h), (0, 0, 0))
        left = (tgt_w - new_w) // 2
        top = (tgt_h - new_h) // 2
        canvas.paste(resized, (left, top))
        return canvas

    def _safe_json_dumps(self, obj, ensure_ascii=False, indent=2):
        """
        å®‰å…¨åœ°åºåˆ—åŒ–JSONå¯¹è±¡ï¼Œå¤„ç†åŒ…å«base64çš„å­—æ®µ
        """
        def _process_value(value):
            if isinstance(value, str) and len(value) > 100 and (
                value.startswith('data:image/') or 
                value.startswith('iVBORw0KGgo') or  # PNG base64å¼€å¤´
                value.startswith('/9j/') or          # JPEG base64å¼€å¤´
                all(c in 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=' for c in value[:20])  # base64ç‰¹å¾
            ):
                return self._truncate_base64_log(value)
            elif isinstance(value, dict):
                return {k: _process_value(v) for k, v in value.items()}
            elif isinstance(value, list):
                return [_process_value(v) for v in value]
            else:
                return value
        
        processed_obj = _process_value(obj)
        return json.dumps(processed_obj, ensure_ascii=ensure_ascii, indent=indent)

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "OpenAI_Image_API": OpenAIImageAPI
}
NODE_DISPLAY_NAME_MAPPINGS = {
    "OpenAI_Image_API": "ğŸ¦‰OpenAIå…¼å®¹Image APIèŠ‚ç‚¹"
} 
