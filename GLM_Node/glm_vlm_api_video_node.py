import os
import json
import requests
import time
import jwt
import re

class GLMVLMAPIVideo:
    """
    ComfyUIè‡ªå®šä¹‰èŠ‚ç‚¹ï¼šGLM VLM APIè§†é¢‘URLèŠ‚ç‚¹
    åªæ”¯æŒè§†é¢‘URLæ¨ç†ï¼Œvideo_urlä¸ºå¿…å¡«å‚æ•°ã€‚
    è¾“å…¥å‚æ•°ï¼švideo_url, model, max_tokens, temperature, top_p, system_prompt, user_prompt
    è¾“å‡ºï¼šreasoning_contentï¼ˆæ€è€ƒè¿‡ç¨‹ï¼‰, answerï¼ˆæœ€ç»ˆç­”æ¡ˆï¼‰, tokens_usageï¼ˆAPIç”¨é‡ä¿¡æ¯ï¼‰
    """
    def __init__(self):
        # è¯»å–é…ç½®æ–‡ä»¶ï¼Œå®¹é”™åŒ¹é… VLM ä¸‹çš„æä¾›æ–¹ï¼ˆä¼˜å…ˆâ€œæ™ºè°±å®˜æ–¹â€ï¼Œå¦åˆ™å›é€€åˆ°ç¬¬ä¸€ä¸ªå« model åˆ—è¡¨çš„æä¾›æ–¹ï¼‰
        config_path = os.path.join(os.path.dirname(__file__), '..', 'config.json')
        with open(config_path, 'r', encoding='utf-8') as f:
            cfg_all = json.load(f)
        vlm = cfg_all.get('VLM', {}) or {}
        provider_key = None
        if "æ™ºè°±å®˜æ–¹" in vlm and isinstance(vlm["æ™ºè°±å®˜æ–¹"], dict):
            provider_key = "æ™ºè°±å®˜æ–¹"
        else:
            for k, v in vlm.items():
                if isinstance(v, dict) and isinstance(v.get('model'), list):
                    provider_key = k
                    break
        self.config = vlm.get(provider_key, {})

    @classmethod
    def INPUT_TYPES(cls):
        # åŠ¨æ€è¯»å–æ¨¡å‹é€‰é¡¹ï¼ˆå®¹é”™åŒ¹é…â€œæ™ºè°±å®˜æ–¹â€ï¼Œå¦åˆ™å›é€€åˆ°ç¬¬ä¸€ä¸ªåŒ…å« model åˆ—è¡¨çš„æä¾›æ–¹ï¼‰
        config_path = os.path.join(os.path.dirname(__file__), '..', 'config.json')
        with open(config_path, 'r', encoding='utf-8') as f:
            cfg_all = json.load(f)
        vlm = cfg_all.get('VLM', {}) or {}
        selected = {}
        if "æ™ºè°±å®˜æ–¹" in vlm and isinstance(vlm["æ™ºè°±å®˜æ–¹"], dict):
            selected = vlm["æ™ºè°±å®˜æ–¹"]
        else:
            for k, v in vlm.items():
                if isinstance(v, dict) and isinstance(v.get('model'), list):
                    selected = v
                    break
        model_options = selected.get('model', ['glm-4.1v-thinking-flashx'])
        return {
            "required": {
                "video_url": ("STRING", {"tooltip": "è§†é¢‘URLåœ°å€ï¼Œå¿…å¡«ï¼Œæ”¯æŒhttp(s)é“¾æ¥"}),
                "model": (model_options, {"default": model_options[0]}),
                "max_tokens": ("INT", {"default": 512, "min": 1, "max": 8192, "step": 1}),
                "temperature": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.01}),
                "top_p": ("FLOAT", {"default": 0.6, "min": 0.0, "max": 1.0, "step": 0.01}),
                "system_prompt": ("STRING", {"multiline": True, "default": "ä½ æ˜¯ä¸€ä¸ªè§†è§‰æ¨ç†ä¸“å®¶ã€‚"}),
                "user_prompt": ("STRING", {"multiline": True, "default": "è¯·ä»”ç»†æè¿°è¿™ä¸ªè§†é¢‘ã€‚"}),
            }
        }

    RETURN_TYPES = ("STRING", "STRING", "STRING")
    RETURN_NAMES = ("reasoning_content", "answer", "tokens_usage")
    FUNCTION = "infer"
    CATEGORY = "ğŸ¦‰FreeAPI/GLM"

    def infer(self, video_url, model, max_tokens, temperature, top_p, system_prompt, user_prompt):
        base_url = self.config.get('base_url', 'https://open.bigmodel.cn/api/paas/v4')
        api_key = self.config.get('api_key', '')
        if not api_key:
            return ("", "é”™è¯¯ï¼šæœªé…ç½®GLM API Keyï¼Œè¯·åœ¨config.jsonçš„ VLM éƒ¨åˆ†å¯¹åº”æä¾›æ–¹ä¸‹è®¾ç½® api_keyï¼ˆä¾‹å¦‚â€œæ™ºè°±å®˜æ–¹â€.api_keyï¼‰", "")
        if not self._is_valid_url(video_url):
            return ("", "é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆçš„è§†é¢‘URLï¼ˆhttp/httpså¼€å¤´ï¼‰", "")
        messages = [
            {"role": "system", "content": system_prompt or "ä½ æ˜¯ä¸€ä¸ªè§†è§‰æ¨ç†ä¸“å®¶ã€‚"},
            {"role": "user", "content": [
                {"type": "video_url", "video_url": {"url": video_url.strip()}},
                {"type": "text", "text": user_prompt}
            ]}
        ]
        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "top_p": top_p
        }
        try:
            headers = self._build_headers(api_key)
            resp = requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=180)
            resp.raise_for_status()
            return self._parse_response(resp)
        except requests.exceptions.RequestException as e:
            return ("", f"APIè¯·æ±‚å¤±è´¥: {e}", "")
        except Exception as e:
            return ("", f"å¤„ç†å¤±è´¥: {e}", "")

    def _is_valid_url(self, url):
        try:
            return url and url.strip().startswith(('http://', 'https://'))
        except:
            return False

    def _parse_response(self, resp):
        try:
            data = resp.json()
            usage = data.get("usage", {})
            tokens_usage = self._format_tokens_usage(usage)
            if "choices" in data and data["choices"]:
                message = data["choices"][0]["message"]
                content = message.get("content", "")
                reasoning_content = message.get("reasoning_content", None)
                if reasoning_content is None:
                    reasoning_content, answer = self._parse_content_tags(content)
                else:
                    answer = content
                return (reasoning_content or "", answer, tokens_usage)
            else:
                return ("", f"APIè¿”å›å¼‚å¸¸: {str(data)}", tokens_usage)
        except Exception as e:
            return ("", f"å“åº”è§£æå¤±è´¥: {e}", "")

    def _format_tokens_usage(self, usage):
        if not usage:
            return ""
        return f"total_tokens={usage.get('total_tokens', '-')}, input_tokens={usage.get('prompt_tokens', '-')}, output_tokens={usage.get('completion_tokens', '-')}"

    def _parse_content_tags(self, content):
        try:
            pattern = r'<think>(.*?)</think>'
            match = re.search(pattern, content, re.DOTALL)
            if match:
                reasoning_content = match.group(1).strip()
                answer = content.replace(match.group(0), "").strip()
            else:
                answer_match = re.search(r'<answer>(.*?)</answer>', content, re.DOTALL)
                if answer_match:
                    answer = answer_match.group(1).strip()
                    reasoning_content = ""
                else:
                    answer_match = re.search(r'<answer>(.*)', content, re.DOTALL)
                    if answer_match:
                        answer = answer_match.group(1).strip()
                        reasoning_content = ""
                    else:
                        answer = content.strip()
                        reasoning_content = ""
            return (reasoning_content, answer)
        except Exception as e:
            return ("", content.strip())

    def _build_headers(self, api_key):
        try:
            api_key_id, api_key_secret = api_key.split('.')
            payload = {
                "api_key": api_key_id,
                "exp": int(round(time.time() * 1000)) + 3600 * 1000,
                "timestamp": int(round(time.time() * 1000)),
            }
            token = jwt.encode(payload, api_key_secret, algorithm="HS256", headers={"alg": "HS256", "sign_type": "SIGN"})
            return {
                "Authorization": f"Bearer {token}",
                "Content-Type": "application/json"
            }
        except Exception as e:
            return {"Authorization": "Bearer error", "Content-Type": "application/json"}

NODE_CLASS_MAPPINGS = {
    "GLM_VLM_API_VIDEO": GLMVLMAPIVideo
}
NODE_DISPLAY_NAME_MAPPINGS = {
    "GLM_VLM_API_VIDEO": "ğŸ¦‰GLM VLM APIè§†é¢‘æ¨ç†èŠ‚ç‚¹"
} 