import os
import json
import time
from io import BytesIO

import requests
from PIL import Image
import numpy as np
import torch


class HAIYIImageNode:
    """
    ComfyUI è‡ªå®šä¹‰èŠ‚ç‚¹ï¼šHaiyi Imageï¼ˆæµ·è‰ºæ–‡ç”Ÿå›¾ï¼‰

    åŠŸèƒ½ï¼š
    1. æäº¤æµ·è‰ºã€Œæ–‡ç”Ÿå›¾ã€ä»»åŠ¡åˆ° /api/v1/creativity/generate/apply
    2. è½®è¯¢ /api/v1/task/batch-progress ç›´åˆ°ç”Ÿæˆå®Œæˆ
    3. ä¸‹è½½é¦–å¼ å›¾ç‰‡ï¼Œè½¬æ¢ä¸º ComfyUI IMAGE å¼ é‡
    4. è¿”å› (image, generation_info)

    è®¤è¯ï¼š
    - åœ¨ä¸æœ¬æ–‡ä»¶åŒç›®å½•çš„ haiyi_config.json ä¸­é…ç½® Cookie ä¸æ¨¡å‹æ˜ å°„
      {"cookie": "deviceId=...; T=...", "image_models": {"Seedream 4.0": {"apply_id": "...", "ver_no": "...", "ss": 52}}}

    é‡è¦è¯´æ˜ï¼š
    - æµ·è‰ºæ¥å£éœ€è¦æœ‰æ•ˆç™»å½• Cookieã€‚è¯·åœ¨ haiyi_config.json çš„ cookie å­—æ®µå¡«å…¥ä½ çš„æ•´ä¸² Cookieã€‚
    - è‹¥æ¥å£å­—æ®µå˜æ›´ï¼Œè¯·æŒ‰å®é™…è¿”å›é€‚é…è§£æé€»è¾‘ã€‚
    """

    def __init__(self):
        # è¯»å–é…ç½®æ–‡ä»¶
        self.config_path = os.path.join(os.path.dirname(__file__), "haiyi_config.json")
        if not os.path.exists(self.config_path):
            raise RuntimeError("ç¼ºå°‘é…ç½®æ–‡ä»¶ haiyi_config.jsonï¼Œè¯·å…ˆåˆ›å»ºå¹¶å¡«å†™ cookie ä¸æ¨¡å‹é…ç½®ã€‚")
        with open(self.config_path, "r", encoding="utf-8") as f:
            self.config = json.load(f)

        # åŸºæœ¬é…ç½®
        self.cookie = self.config.get("cookie", "").strip()
        if not self.cookie:
            raise RuntimeError("haiyi_config.json æœªé…ç½® cookieï¼Œè¯·ç²˜è´´ä½ çš„æµ·è‰ºè´¦å· Cookie åˆ° cookie å­—æ®µã€‚")

        self.timeout = int(self.config.get("timeout", 30))
        self.max_wait_time = int(self.config.get("max_wait_time", 300))
        self.check_interval = int(self.config.get("check_interval", 2))

        # headers
        headers_cfg = self.config.get("headers", {}) or {}
        self.base_headers = {
            "accept": "application/json, text/plain, */*",
            "accept-language": "zhCN",
            "cache-control": "no-cache",
            "content-type": "application/json",
            "origin": headers_cfg.get("origin", "https://www.haiyi.art"),
            "pragma": "no-cache",
            "priority": "u=1, i",
            "referer": headers_cfg.get("referer", "https://www.haiyi.art/"),
            "sec-ch-ua": '"Microsoft Edge";v="141", "Not?A_Brand";v="8", "Chromium";v="141"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "same-origin",
            "user-agent": headers_cfg.get("user-agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36 Edg/141.0.0.0"),
            "x-app-id": headers_cfg.get("x-app-id", "web_global_seaart"),
            "x-platform": headers_cfg.get("x-platform", "web"),
            # Cookie é€šè¿‡ headers ä¼ å…¥ï¼ˆç­‰ä»·äº curl -bï¼‰
            "Cookie": self.cookie,
        }

        # æ¨¡å‹æ˜ å°„
        self.models = self.config.get("image_models", {})
        if not self.models:
            raise RuntimeError("haiyi_config.json æœªé…ç½® modelsï¼Œè¯·è‡³å°‘é…ç½® Seedream 4.0 çš„ apply_id/ver_no/ssã€‚")

        # API åŸºç¡€åœ°å€
        self.base_url = "https://www.haiyi.art"

    @classmethod
    def INPUT_TYPES(cls):
        """
        å®šä¹‰èŠ‚ç‚¹è¾“å…¥ï¼š
        - å¿…é€‰ï¼šmodel(ä¸‹æ‹‰ï¼Œé»˜è®¤ Seedream 4.0)ï¼Œprompt(å¤šè¡Œæ–‡æœ¬)
        - å¯é€‰ï¼šratio(é»˜è®¤ 3:4)ï¼Œresolution(æ–°å¢ï¼Œæ”¯æŒ1K/2K/4Kï¼Œé»˜è®¤1K)
        """
        # åŠ¨æ€è¯»å–æ¨¡å‹é€‰é¡¹
        config_path = os.path.join(os.path.dirname(__file__), "haiyi_config.json")
        try:
            with open(config_path, "r", encoding="utf-8") as f:
                cfg = json.load(f)
            model_names = list(cfg.get("image_models", {}).keys())
            if not model_names:
                model_names = ["Seedream 4.0"]
        except Exception:
            model_names = ["Seedream 4.0"]

        default_model = "Seedream 4.0" if "Seedream 4.0" in model_names else model_names[0]

        return {
            "required": {
                "model": (model_names, {"default": default_model}),
                "prompt": ("STRING", {"multiline": True, "default": "æ¶²æ€é‡‘å±è£…ç”²ï¼ŒæœºåŠ¨æ­¦ç¥"}),
            },
            "optional": {
                "ratio": (["1:1", "3:4", "4:3", "9:16", "16:9", "2:3", "3:2", "4:5", "5:4", "21:9", "auto"], {"default": "3:4"}),
                "resolution": (["1K", "2K", "4K"], {"default": "1K"}),
                "image": ("IMAGE",),
            },
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("image", "generation_info")
    FUNCTION = "generate"
    CATEGORY = "ğŸ¦‰FreeAPI/Haiyi"

    def generate(self, model: str, prompt: str, ratio: str = "3:4", resolution: str = "1K", image=None):
        """
        æ ¸å¿ƒæµç¨‹ï¼š
        - è‹¥æä¾› image(IMAGE)ï¼šæŒ‰å›¾ç”Ÿå›¾æµç¨‹
          1) é¢„ç­¾å -> PUT ä¸Šä¼  -> ç¡®è®¤ä¸Šä¼  -> è·å¾— url
          2) è°ƒç”¨ apply(image+prompt) -> task_id
        - å¦åˆ™ï¼šæŒ‰æ–‡ç”Ÿå›¾æµç¨‹
          1) è°ƒç”¨ apply(prompt+ratio+resolution) -> task_id
        - ç»Ÿä¸€ï¼šè½®è¯¢ batch-progress -> ä¸‹è½½é¦–å›¾ -> è¿”å›
        """
        model_cfg = self.models.get(model, None)
        if not model_cfg:
            raise RuntimeError(f"æœªæ‰¾åˆ°æ¨¡å‹é…ç½®ï¼š{model}ï¼Œè¯·åœ¨ haiyi_config.json çš„ models ä¸­æ·»åŠ ã€‚")

        ss = int(model_cfg.get("ss", 52))

        # åˆ†æ”¯ï¼šå›¾ç”Ÿå›¾ or æ–‡ç”Ÿå›¾
        # æµ·è‰ºå½±åƒ 2.0ï¼ˆå®˜æ–¹å¸¸è§„æ–‡ç”Ÿå›¾ï¼‰åˆ†æ”¯ï¼šä»…æ”¯æŒæ–‡ç”Ÿå›¾ï¼Œå¿½ç•¥ imageï¼›è¯¥æ¨¡å‹ä¸éœ€è¦ apply_id/ver_no
        if model == "æµ·è‰ºå½±åƒ 2.0":
            if image is not None:
                print("[Haiyi] æç¤º: 'æµ·è‰ºå½±åƒ 2.0'ä»…æ”¯æŒæ–‡ç”Ÿå›¾ï¼Œimage è¾“å…¥å°†è¢«å¿½ç•¥")
            t2i_cfg = model_cfg
            model_no = str(t2i_cfg.get("model_no", "")).strip()
            model_ver_no = str(t2i_cfg.get("model_ver_no", "")).strip()
            if not model_no or not model_ver_no:
                raise RuntimeError("æµ·è‰ºå½±åƒ 2.0 é…ç½®ç¼ºå°‘ model_no æˆ– model_ver_no")
            width, height = self._size_from_ratio(ratio)
            steps = int(t2i_cfg.get("default_steps", 20))
            cfg_scale = float(t2i_cfg.get("default_cfg_scale", 2.5))
            n_iter = int(t2i_cfg.get("default_n_iter", 4))
            seed = int(time.time()) % 4294967295
            payload = {
                "model_no": model_no,
                "model_ver_no": model_ver_no,
                "channel_id": "",
                "speed_type": 2,
                "meta": {
                    "prompt": prompt,
                    "negative_prompt": "",
                    "width": width,
                    "height": height,
                    "steps": steps,
                    "cfg_scale": cfg_scale,
                    "sampler_name": "",
                    "n_iter": n_iter,
                    "lora_models": [],
                    "vae": "None",
                    "clip_skip": 0,
                    "seed": seed,
                    "restore_faces": False,
                    "embeddings": [],
                    "generate": {"anime_enhance": 0, "mode": 0, "gen_mode": 1, "prompt_magic_mode": 2},
                    "original_translated_meta_prompt": prompt,
                    "artwork_remix_local_prompt": prompt,
                },
                "ss": ss,
            }
            print(f"[Haiyi] æäº¤å¸¸è§„æ–‡ç”Ÿå›¾å‚æ•°: model_no={model_no}, model_ver_no={model_ver_no}, size={width}x{height}")
            task_id, err = self._submit_text_to_img(payload)
            if err:
                info = f"æ¨¡å‹: {model}\næ¯”ä¾‹: {ratio}\nåˆ†è¾¨ç‡: {resolution}\né”™è¯¯: {err}"
                print(f"[Haiyi] æäº¤å¤±è´¥: {err}")
                return (self._blank_image_tensor(), info)
            print(f"[Haiyi] ä»»åŠ¡æäº¤è¿”å› task_id={task_id}")
        else:
            apply_id = str(model_cfg.get("apply_id", "")).strip()
            ver_no = str(model_cfg.get("ver_no", "")).strip()
            if not apply_id:
                raise RuntimeError(f"æ¨¡å‹ {model} ç¼ºå°‘ apply_idã€‚")

            # NanoBananaPro ç³»åˆ—æ¨¡å‹åˆ†æ”¯
            if model in ["NanoBananaPro_T2I", "NanoBananaPro_I2I"]:
                if model == "NanoBananaPro_T2I" and image is not None:
                    print("[Haiyi] æç¤º: 'NanoBananaPro_T2I'ä»…æ”¯æŒæ–‡ç”Ÿå›¾ï¼Œimage è¾“å…¥å°†è¢«å¿½ç•¥")
                if model == "NanoBananaPro_I2I" and image is None:
                    raise RuntimeError("NanoBananaPro_I2I éœ€è¦è¾“å…¥å›¾ç‰‡")
                
                if image is not None and model == "NanoBananaPro_I2I":
                    # å›¾ç”Ÿå›¾æµç¨‹
                    print(f"[Haiyi] NanoBananaProå›¾ç”Ÿå›¾æµç¨‹å¼€å§‹ï¼Œratio={ratio}, resolution={resolution}")
                    img_url = self._upload_image_presign(image, apply_id)
                    print(f"[Haiyi] ä¸Šä¼ å®Œæˆï¼Œè¿”å›URL: {img_url}")
                    inputs = [
                        {"field": "image", "node_id": "4", "node_type": "LoadImage", "val": img_url},
                        {"field": "image", "node_id": "5", "node_type": "LoadImage", "val": img_url},
                        {"field": "image", "node_id": "6", "node_type": "LoadImage", "val": img_url},
                        {"field": "prompt", "node_id": "1", "node_type": "HaiYiNanoBananaPro", "val": prompt},
                        {"field": "resolution", "node_id": "1", "node_type": "HaiYiNanoBananaPro", "val": resolution},
                        {"field": "aspect_ratio", "node_id": "1", "node_type": "HaiYiNanoBananaPro", "val": ratio},
                    ]
                else:
                    # æ–‡ç”Ÿå›¾æµç¨‹
                    print(f"[Haiyi] NanoBananaProæ–‡ç”Ÿå›¾æµç¨‹å¼€å§‹ï¼Œratio={ratio}, resolution={resolution}")
                    inputs = [
                        {"field": "prompt", "node_id": "1", "node_type": "HaiYiNanoBananaPro", "val": prompt},
                        {"field": "resolution", "node_id": "1", "node_type": "HaiYiNanoBananaPro", "val": resolution},
                        {"field": "aspect_ratio", "node_id": "1", "node_type": "HaiYiNanoBananaPro", "val": ratio},
                    ]
                payload = {"apply_id": apply_id, "inputs": inputs, "ss": ss}
            else:
                # åŸæœ‰æ¨¡å‹åˆ†æ”¯ï¼ˆSeedream 4.0, NanoBananaç­‰ï¼‰
                if image is not None:
                    print(f"[Haiyi] å›¾ç”Ÿå›¾æµç¨‹å¼€å§‹ï¼Œæ¨¡å‹={model}ï¼Œratio={ratio}")
                    img_url = self._upload_image_presign(image, apply_id)
                    print(f"[Haiyi] ä¸Šä¼ å®Œæˆï¼Œè¿”å›URL: {img_url}")
                    if model == "NanoBanana":
                        inputs = [
                            {"field": "image", "node_id": "2", "node_type": "LoadImage", "val": img_url},
                            {"field": "prompt", "node_id": "4", "node_type": "SeaArtNanoBanana", "val": prompt},
                        ]
                        payload = {"apply_id": apply_id, "inputs": inputs, "ver_no": ver_no, "ss": ss}
                    else:
                        inputs = [
                            {"field": "image", "node_id": "3", "node_type": "LoadImage", "val": img_url},
                            {"field": "value", "node_id": "10", "node_type": "String-ğŸ”¬", "val": prompt},
                        ]
                        payload = {"apply_id": apply_id, "inputs": inputs, "ss": ss}
                else:
                    print(f"[Haiyi] æ–‡ç”Ÿå›¾æµç¨‹å¼€å§‹ï¼Œæ¨¡å‹={model}ï¼Œratio={ratio}")
                    if model == "NanoBanana":
                        inputs = [
                            {"field": "prompt", "node_id": "4", "node_type": "SeaArtNanoBanana", "val": prompt},
                        ]
                        payload = {"apply_id": apply_id, "inputs": inputs, "ver_no": ver_no, "ss": ss}
                    else:
                        inputs = [
                            {"field": "value", "node_id": "11", "node_type": "String-ğŸ”¬", "val": prompt},
                            {"field": "ratio", "node_id": "10", "node_type": "HaiYiFilmEdit", "val": ratio},
                            {"field": "resolution", "node_id": "10", "node_type": "HaiYiFilmEdit", "val": "2K"},
                        ]
                        payload = {"apply_id": apply_id, "inputs": inputs, "ver_no": ver_no, "ss": ss}
            
            if 'inputs' in locals():
                print(f"[Haiyi] æäº¤å‚æ•°æ‘˜è¦: apply_id={apply_id}, ver_no={ver_no if 'ver_no' in locals() else 'N/A'}, ss={ss}, inputs={inputs}")
            task_id, err = self._submit_task(payload)
            if err:
                info = f"æ¨¡å‹: {model}\næ¯”ä¾‹: {ratio}\nåˆ†è¾¨ç‡: {resolution}\né”™è¯¯: {err}"
                print(f"[Haiyi] æäº¤å¤±è´¥: {err}")
                return (self._blank_image_tensor(), info)
            print(f"[Haiyi] ä»»åŠ¡æäº¤è¿”å› task_id={task_id}")        

        img_urls, raw_progress = self._wait_for_finish(task_id, ss)
        print(f"[Haiyi] ä»»åŠ¡è½®è¯¢å®Œæˆï¼Œç»“æœURLs={img_urls}")
        if not img_urls:
            raise RuntimeError(f"ç”Ÿæˆå¤±è´¥æˆ–è¶…æ—¶ï¼Œæœªå–å¾—å›¾ç‰‡é“¾æ¥ã€‚æœ€è¿‘ä¸€æ¬¡è¿”å›ï¼š{raw_progress}")

        # å°†æ‰€æœ‰è¿”å› URL ä¸‹è½½ä¸ºæ‰¹é‡å¼ é‡ï¼›è‹¥åªæœ‰1å¼ åˆ™é€€åŒ–ä¸ºå•å¼ 
        image_tensor = self._download_images_to_tensor(img_urls[:4] if img_urls else img_urls)

        # ç»„ç»‡ generation_info æ–‡æœ¬ï¼ˆåŒ…å«å…³é”®ä¿¡æ¯ä¸æœ€å¤šå››å¼ å›¾ç‰‡ç›´é“¾ï¼‰
        info_lines = [
            f"âœ¨ æ¨¡å‹: {model}",
            f"ğŸ“ æ¯”ä¾‹: {ratio}",
            f"ğŸ“± åˆ†è¾¨ç‡: {resolution}",
            f"ğŸ”– ä»»åŠ¡ID: {task_id}",
            "ğŸ”— å›¾ç‰‡é“¾æ¥:" ,
        ]
        for i, u in enumerate(img_urls[:4]):
            info_lines.append(f"[{i}] {u}")
        # è¿½åŠ å‰©ä½™ç§¯åˆ†ä¿¡æ¯
        try:
            coins = self._fetch_remaining_temp_coins()
            if coins is not None:
                info_lines.append(f"ğŸª™ å‰©ä½™ç§¯åˆ†: {coins}")
                print(f"[Haiyi] å‰©ä½™ç§¯åˆ†: {coins}")
            else:
                print("[Haiyi] è·å–å‰©ä½™ç§¯åˆ†å¤±è´¥æˆ–æ— è¿”å›")
        except Exception as e:
            print(f"[Haiyi] è·å–å‰©ä½™ç§¯åˆ†å¼‚å¸¸: {e}")
        generation_info = "\n".join(info_lines)
        print(f"[Haiyi] generation_info:\n{generation_info}")

        return (image_tensor, generation_info)

    # =============== å†…éƒ¨æ–¹æ³• ===============

    def _submit_task(self, payload: dict):
        url = f"{self.base_url}/api/v1/creativity/generate/apply"
        print(f"[Haiyi] POST {url}")
        try:
            resp = requests.post(url, headers=self.base_headers, data=json.dumps(payload), timeout=self.timeout)
            resp.raise_for_status()
            data = resp.json()
        except Exception as e:
            return None, f"æäº¤ä»»åŠ¡è¯·æ±‚å¤±è´¥: {e}"
        # ç»Ÿä¸€å¤„ç†çŠ¶æ€ç 
        try:
            status = (data or {}).get("status", {})
            code = status.get("code")
            msg = status.get("msg") or ""
            if code == 10000:
                task_id = (data.get("data") or {}).get("id")
                return task_id, None
            if code == 70026:
                return None, "æ‚¨çš„æç¤ºè¯ä¸­å«æœ‰æ•æ„Ÿè¯æ±‡ï¼Œè¯·ä¿®æ”¹åå†è¯•"
            return None, f"æäº¤å¤±è´¥: code={code}, msg={msg}"
        except Exception:
            return None, "æäº¤å¤±è´¥: æœªçŸ¥å“åº”æ ¼å¼"

    def _submit_text_to_img(self, payload: dict):
        url = f"{self.base_url}/api/v1/task/v2/text-to-img"
        print(f"[Haiyi] POST {url}")
        try:
            resp = requests.post(url, headers=self.base_headers, data=json.dumps(payload), timeout=self.timeout)
            resp.raise_for_status()
            data = resp.json()
        except Exception as e:
            return None, f"æäº¤å¸¸è§„æ–‡ç”Ÿå›¾å¤±è´¥: {e}"
        try:
            status = (data or {}).get("status", {})
            code = status.get("code")
            msg = status.get("msg") or ""
            if code == 10000:
                task_id = (data.get("data") or {}).get("id")
                return task_id, None
            if code == 70026:
                return None, "æ‚¨çš„æç¤ºè¯ä¸­å«æœ‰æ•æ„Ÿè¯æ±‡ï¼Œè¯·ä¿®æ”¹åå†è¯•"
            return None, f"æäº¤å¤±è´¥: code={code}, msg={msg}"
        except Exception:
            return None, "æäº¤å¤±è´¥: æœªçŸ¥å“åº”æ ¼å¼"

    def _extract_task_id(self, data: dict) -> str:
        task_id = None
        try:
            if isinstance(data, dict) and data.get("status", {}).get("code") == 10000:
                task_id = data.get("data", {}).get("id")
        except Exception:
            task_id = None
        return task_id

    def _wait_for_finish(self, task_id: str, ss: int):
        url = f"{self.base_url}/api/v1/task/batch-progress"
        print(f"[Haiyi] å¼€å§‹è½®è¯¢è¿›åº¦ task_id={task_id}")
        start_time = time.time()
        last_payload = None

        while True:
            if time.time() - start_time > self.max_wait_time:
                print("[Haiyi] è½®è¯¢è¶…æ—¶")
                return None, last_payload

            body = {"task_ids": [task_id], "ss": ss}
            try:
                resp = requests.post(url, headers=self.base_headers, data=json.dumps(body), timeout=self.timeout)
                resp.raise_for_status()
                payload = resp.json()
                last_payload = payload
            except Exception as e:
                last_payload = {"error": str(e)}
                time.sleep(self.check_interval)
                continue

            try:
                items = payload.get("data", {}).get("items", [])
                if not items:
                    time.sleep(self.check_interval)
                    continue
                item = items[0]
                # ä»…æ‰“å°å…³é”®è¿›åº¦å€¼
                try:
                    proc = item.get("process")
                    if proc is not None:
                        print(f"[Haiyi] è¿›åº¦: {proc}%")
                except Exception:
                    pass
                status_code = item.get("status")  # 1 waiting, 3 finished
                if status_code == 3:
                    img_uris = item.get("img_uris") or []
                    # æå– index 0-3 çš„4å¼ å›¾ï¼ŒæŒ‰ index æ’åºï¼Œä¼˜å…ˆå– urlï¼Œæ— åˆ™å– cover_url
                    urls = []
                    try:
                        sorted_uris = sorted(
                            [u for u in img_uris if isinstance(u, dict) and isinstance(u.get("index"), int)],
                            key=lambda x: x.get("index")
                        )
                        for u in sorted_uris:
                            idx = u.get("index")
                            if idx is not None and 0 <= idx <= 3:
                                url_field = u.get("url") or u.get("cover_url")
                                if url_field:
                                    urls.append(url_field)
                    except Exception:
                        # å›é€€ï¼šä¿æŒæ—§é€»è¾‘ï¼Œæ”¶é›†æ‰€æœ‰å­˜åœ¨çš„ url/cover_url
                        for u in img_uris:
                            if isinstance(u, dict):
                                url_field = u.get("url") or u.get("cover_url")
                                if url_field:
                                    urls.append(url_field)
                    return urls, payload
                time.sleep(self.check_interval)
            except Exception:
                time.sleep(self.check_interval)

    def _download_first_image_as_tensor(self, url: str):
        print(f"[Haiyi] ä¸‹è½½å›¾ç‰‡: {url}")
        try:
            r = requests.get(url, headers={"User-Agent": self.base_headers.get("user-agent", "Mozilla/5.0")}, timeout=self.timeout)
            r.raise_for_status()
            img = Image.open(BytesIO(r.content)).convert("RGB")
        except Exception as e:
            raise RuntimeError(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}")

        np_img = np.array(img).astype(np.float32) / 255.0  # H, W, C in [0,1]
        # æ‰©å±• batch ç»´åº¦ -> (1, H, W, C)
        if np_img.ndim == 3:
            np_img = np.expand_dims(np_img, axis=0)
        tensor = torch.from_numpy(np_img.copy())
        return tensor

    def _blank_image_tensor(self, width: int = 256, height: int = 256):
        arr = np.zeros((height, width, 3), dtype=np.float32)  # [H,W,3] zeros
        return torch.from_numpy(arr).unsqueeze(0)  # [1,H,W,3]

    def _size_from_ratio(self, ratio: str):
        # ç®€å•å°ºå¯¸æ˜ å°„ï¼Œæ»¡è¶³å¤§å¤šæ•°éœ€æ±‚ï¼›å¦‚éœ€è°ƒæ•´å¯æ‰©å±•ä¸ºå‚æ•°
        table = {
            "1:1": (2048, 2048),
            "3:4": (1536, 2048),
            "4:3": (2048, 1536),
            "9:16": (1152, 2048),
            "16:9": (2048, 1152),
        }
        return table.get(ratio, (1024, 1024))

    def _download_images_to_tensor(self, image_urls):
        """
        æ‰¹é‡ä¸‹è½½å›¾ç‰‡å¹¶å †å ä¸º [N,H,W,3] çš„ batch å¼ é‡ï¼›è‹¥å°ºå¯¸ä¸ä¸€è‡´ï¼ŒæŒ‰ç¬¬ä¸€å¼ ç»Ÿä¸€ resizeã€‚
        å¿½ç•¥å¤±è´¥é¡¹ï¼›è‹¥å…¨éƒ¨å¤±è´¥åˆ™æŠ›é”™ã€‚
        """
        tensors = []
        target_size = None  # (W,H)
        for idx, url in enumerate(image_urls or []):
            try:
                print(f"[Haiyi] å¼€å§‹ä¸‹è½½ç¬¬{idx+1}å¼ ï¼š{url}")
                r = requests.get(url, headers={"User-Agent": self.base_headers.get("user-agent", "Mozilla/5.0")}, timeout=self.timeout)
                r.raise_for_status()
                img = Image.open(BytesIO(r.content)).convert("RGB")
                if target_size is None:
                    target_size = img.size
                else:
                    if img.size != target_size:
                        img = img.resize(target_size, Image.Resampling.LANCZOS)
                        print(f"[Haiyi] å°ºå¯¸ä¸ä¸€è‡´ï¼Œç»Ÿä¸€ä¸º {target_size[0]}x{target_size[1]}")
                np_img = np.array(img, dtype=np.float32) / 255.0
                tensor_img = torch.from_numpy(np_img).unsqueeze(0)  # [1,H,W,3]
                tensors.append(tensor_img)
            except Exception as e:
                print(f"[Haiyi] ç¬¬{idx+1}å¼ ä¸‹è½½å¤±è´¥ï¼š{e}")
                continue
        if not tensors:
            raise RuntimeError("æ‰€æœ‰å›¾ç‰‡ä¸‹è½½å¤±è´¥")
        batch = torch.cat(tensors, dim=0)  # [N,H,W,3]
        print(f"[Haiyi] æœ€ç»ˆtensor batch: å½¢çŠ¶={batch.shape}, dtype={batch.dtype}")
        return batch

    # =============== ä¸Šä¼ ç›¸å…³ ===============
    def _upload_image_presign(self, image_tensor, template_id: str) -> str:
        """
        ä¸‰æ­¥ï¼š
        1) é¢„ç­¾å uploadImageByPreSign -> å¾—åˆ° pre_sign ä¸ file_id
        2) PUT ä¸Šä¼ åˆ° pre_sign
        3) confirmImageUploadedByPreSign -> å¾—åˆ°é™æ€CDN url
        è¿”å›ï¼šå›¾ç‰‡ CDN URL
        """
        # å°† ComfyUI IMAGE(tensor) è½¬æ¢ä¸º PNG äºŒè¿›åˆ¶
        pil_img = self._tensor_to_pil(image_tensor)
        img_bytes = BytesIO()
        pil_img.save(img_bytes, format="PNG")
        raw = img_bytes.getvalue()
        file_size = len(raw)
        file_name = f"comfy_{int(time.time())}.png"
        content_type = "image/png"

        # 1) é¢„ç­¾å
        url_presign = f"{self.base_url}/api/v1/resource/uploadImageByPreSign"
        body = {
            "content_type": content_type,
            "file_name": file_name,
            "file_size": file_size,
            "category": 20,
            "hash_val": self._sha256_hex(raw),
            "template_id": template_id,
        }
        print(f"[Haiyi] ä¸Šä¼ é¢„ç­¾å body={body}")
        r = requests.post(url_presign, headers=self.base_headers, data=json.dumps(body), timeout=self.timeout)
        r.raise_for_status()
        data = r.json()
        print(f"[Haiyi] é¢„ç­¾åå“åº”: {data}")
        if data.get("status", {}).get("code") != 10000:
            raise RuntimeError(f"é¢„ç­¾åå¤±è´¥: {data}")
        pre_sign = data.get("data", {}).get("pre_sign")
        file_id = data.get("data", {}).get("file_id")
        if not pre_sign or not file_id:
            raise RuntimeError("é¢„ç­¾åè¿”å›ç¼ºå°‘ pre_sign æˆ– file_id")

        # 2) PUT ä¸Šä¼ 
        put_headers = {
            "Accept": "*/*",
            "Content-Type": content_type,
            "Origin": "https://www.haiyi.art",
            "Referer": "https://www.haiyi.art/",
            "User-Agent": self.base_headers.get("user-agent", "Mozilla/5.0"),
        }
        print(f"[Haiyi] PUT ä¸Šä¼ åˆ° pre_sign: {pre_sign}ï¼Œå¤§å°={file_size}")
        put_resp = requests.put(pre_sign, data=raw, headers=put_headers, timeout=self.timeout)
        put_resp.raise_for_status()

        # 3) ç¡®è®¤ä¸Šä¼ 
        url_confirm = f"{self.base_url}/api/v1/resource/confirmImageUploadedByPreSign"
        confirm_body = {"category": 20, "file_id": file_id, "template_id": template_id}
        print(f"[Haiyi] ç¡®è®¤ä¸Šä¼  body={confirm_body}")
        c = requests.post(url_confirm, headers=self.base_headers, data=json.dumps(confirm_body), timeout=self.timeout)
        c.raise_for_status()
        c_data = c.json()
        print(f"[Haiyi] ç¡®è®¤ä¸Šä¼ å“åº”: {c_data}")
        if c_data.get("status", {}).get("code") != 10000:
            raise RuntimeError(f"ç¡®è®¤ä¸Šä¼ å¤±è´¥: {c_data}")
        url = c_data.get("data", {}).get("url")
        if not url:
            raise RuntimeError("ç¡®è®¤ä¸Šä¼ è¿”å›ç¼ºå°‘ url")
        return url

    def _tensor_to_pil(self, image_tensor) -> Image.Image:
        # ComfyUI IMAGE: (B,H,W,C) float32 [0,1]
        if image_tensor is None:
            raise RuntimeError("ä¼ å…¥ç©ºå›¾ç‰‡")
        if isinstance(image_tensor, torch.Tensor):
            arr = image_tensor.detach().cpu().numpy()
        else:
            arr = np.asarray(image_tensor)
        if arr.ndim == 4:
            arr = arr[0]
        arr = (np.clip(arr, 0, 1) * 255.0).astype(np.uint8)
        return Image.fromarray(arr)

    def _sha256_hex(self, raw: bytes) -> str:
        import hashlib
        h = hashlib.sha256()
        h.update(raw)
        return h.hexdigest()

    def _fetch_remaining_temp_coins(self) -> int | None:
        """
        è°ƒç”¨ haiyi æ¥å£è·å–å½“å‰è´¦å·å‰©ä½™ç§¯åˆ†ï¼Œä»…è¿”å› temp_coinsã€‚
        æˆåŠŸè¿”å› intï¼Œå¤±è´¥è¿”å› Noneã€‚
        """
        url = f"{self.base_url}/api/v1/payment/assets/get"
        try:
            r = requests.post(url, headers=self.base_headers, data=json.dumps({}), timeout=self.timeout)
            r.raise_for_status()
            data = r.json()
            if (data or {}).get("status", {}).get("code") == 10000:
                coins = ((data or {}).get("data") or {}).get("temp_coins")
                if isinstance(coins, int):
                    return coins
        except Exception as e:
            print(f"[Haiyi] æŸ¥è¯¢ç§¯åˆ†å¤±è´¥: {e}")
        return None

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "HAIYIImageNode": HAIYIImageNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "HAIYIImageNode": "ğŸ¦‰Haiyi Image",
}
