import os
import json
import requests
import time
import re
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("QwenLLMAPI")

# èŠ‚ç‚¹ä¸»ç±»
class QwenLLMAPI:
    """
    ComfyUIè‡ªå®šä¹‰èŠ‚ç‚¹ï¼šQwen LLM API
    å®ç°æ–‡æœ¬å¯¹è¯APIè°ƒç”¨ï¼Œä¸“é—¨é’ˆå¯¹Qwen APIï¼Œå‚æ•°è‡ªåŠ¨è¯»å–config.jsonã€‚
    è¾“å…¥å‚æ•°ï¼šmodel, max_tokens, temperature, top_p, system_prompt, user_prompt, enable_thinking, thinking_budget, stream
    è¾“å‡ºï¼šreasoning_contentï¼ˆæ€è€ƒè¿‡ç¨‹ï¼‰, answerï¼ˆæœ€ç»ˆç­”æ¡ˆï¼‰, tokens_usageï¼ˆAPIç”¨é‡ä¿¡æ¯ï¼‰
    """
    def __init__(self):
        # è¯»å–é…ç½®æ–‡ä»¶ï¼Œå®¹é”™åŒ¹é… LLM ä¸‹çš„æä¾›æ–¹ï¼ˆæ”¯æŒé‡å‘½åä¸ºâ€œåƒé—®ç™¾ç‚¼â€ç­‰ï¼‰
        config_path = os.path.join(os.path.dirname(__file__), '..', 'config.json')
        with open(config_path, 'r', encoding='utf-8') as f:
            cfg_all = json.load(f)
        llm = cfg_all.get('LLM', {}) or {}
        # ä¼˜å…ˆåŒ¹é…â€œåƒé—®ç™¾ç‚¼â€ï¼Œå¦åˆ™å›é€€åˆ°ç¬¬ä¸€ä¸ªå«æœ‰ model åˆ—è¡¨çš„æä¾›æ–¹
        provider_key = None
        if "åƒé—®ç™¾ç‚¼" in llm and isinstance(llm["åƒé—®ç™¾ç‚¼"], dict):
            provider_key = "åƒé—®ç™¾ç‚¼"
        else:
            # éå†æ‰¾åˆ°ç¬¬ä¸€ä¸ªå«æœ‰ model åˆ—è¡¨çš„é¡¹
            for k, v in llm.items():
                if isinstance(v, dict) and isinstance(v.get('model'), list):
                    provider_key = k
                    break
        self.config = llm.get(provider_key, {})

    @classmethod
    def INPUT_TYPES(cls):
        # åŠ¨æ€è¯»å–æ¨¡å‹é€‰é¡¹ï¼ˆå®¹é”™åŒ¹é…æä¾›æ–¹ï¼‰
        config_path = os.path.join(os.path.dirname(__file__), '..', 'config.json')
        with open(config_path, 'r', encoding='utf-8') as f:
            cfg_all = json.load(f)
        llm = cfg_all.get('LLM', {}) or {}
        selected = {}
        if "åƒé—®ç™¾ç‚¼" in llm and isinstance(llm["åƒé—®ç™¾ç‚¼"], dict):
            selected = llm["åƒé—®ç™¾ç‚¼"]
        else:
            for k, v in llm.items():
                if isinstance(v, dict) and isinstance(v.get('model'), list):
                    selected = v
                    break
        model_options = selected.get('model', ['qwen-turbo-2025-04-28'])
        return {
            "required": {
                "model": (model_options, {"default": model_options[0]}),
                "max_tokens": ("INT", {"default": 512, "min": 1, "max": 8192, "step": 1}),
                "temperature": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.01}),
                "top_p": ("FLOAT", {"default": 0.6, "min": 0.0, "max": 1.0, "step": 0.01}),
                "system_prompt": ("STRING", {"multiline": True, "default": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"}),
                "user_prompt": ("STRING", {"multiline": True, "default": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}),
                "enable_thinking": ("BOOLEAN", {"default": False, "tooltip": "æ˜¯å¦å¯ç”¨æ€è€ƒè¿‡ç¨‹"}),
                "thinking_budget": ("INT", {"default": 50, "min": 1, "max": 1000, "step": 1, "tooltip": "æ€è€ƒè¿‡ç¨‹çš„æœ€å¤§Tokenæ•°"}),
                "stream": ("BOOLEAN", {"default": False, "tooltip": "æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º"}),
            }
        }

    RETURN_TYPES = ("STRING", "STRING", "STRING")
    RETURN_NAMES = ("reasoning_content", "answer", "tokens_usage")
    FUNCTION = "infer"
    CATEGORY = "ğŸ¦‰FreeAPI/Qwen"

    def infer(self, model, max_tokens, temperature, top_p, system_prompt, user_prompt, enable_thinking=False, thinking_budget=50, stream=False):
        """
        ä¸»æ¨ç†æ–¹æ³•ï¼š
        1. æ„é€ Qwen APIè¯·æ±‚
        2. å‘é€è¯·æ±‚ï¼Œè¿”å›æ–‡æœ¬
        3. è§£æå“åº”ï¼Œæå–æ€è€ƒè¿‡ç¨‹å’Œç­”æ¡ˆ
        """
        # è¯»å–Qwen APIå‚æ•°
        base_url = self.config.get('base_url', 'https://dashscope.aliyuncs.com/compatible-mode/v1')
        api_key = self.config.get('api_key', '')
        
        if not api_key:
            return ("", "é”™è¯¯ï¼šæœªé…ç½®Qwen API Keyï¼Œè¯·åœ¨config.jsonçš„ LLM éƒ¨åˆ†å¯¹åº”æä¾›æ–¹ä¸‹è®¾ç½® api_keyï¼ˆä¾‹å¦‚â€œåƒé—®ç™¾ç‚¼â€.api_keyï¼‰", "")
        
        # 1. æ„é€ æ¶ˆæ¯åˆ—è¡¨
        messages = []
        if system_prompt and system_prompt.strip():
            messages.append({
                "role": "system",
                "content": system_prompt.strip()
            })
        messages.append({
            "role": "user",
            "content": user_prompt
        })
        
        # 2. æ„é€ è¯·æ±‚è½½è·
        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "top_p": top_p
        }
        
        # 3. æ·»åŠ æ€è€ƒè¿‡ç¨‹ç›¸å…³å‚æ•°
        if enable_thinking:
            payload["extra_body"] = {
                "enable_thinking": True,
                "thinking_budget": thinking_budget
            }
        
        # 4. å‘é€è¯·æ±‚
        try:
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            if stream:
                payload["stream"] = True
                resp = requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=180, stream=True)
                return self._parse_stream_response(resp)
            else:
                resp = requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=180)
                return self._parse_response(resp)
                
        except requests.exceptions.RequestException as e:
            logger.info(f"APIè¯·æ±‚å¤±è´¥: {e}")
            return ("", f"APIè¯·æ±‚å¤±è´¥: {e}", "")
        except Exception as e:
            logger.info(f"å¤„ç†å¤±è´¥: {e}")
            return ("", f"å¤„ç†å¤±è´¥: {e}", "")

    def _parse_response(self, resp):
        """
        è§£æéæµå¼å“åº”
        """
        try:
            data = resp.json()
            usage = data.get("usage", {})
            tokens_usage = self._format_tokens_usage(usage)
            
            if "choices" in data and data["choices"]:
                message = data["choices"][0].get("message", {})
                content = message.get("content", "")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ç‹¬ç«‹çš„reasoning_contentå­—æ®µ
                reasoning_content = message.get("reasoning_content", None)
                
                if reasoning_content is not None:
                    # å¦‚æœæœ‰ç‹¬ç«‹çš„reasoning_contentå­—æ®µï¼Œç›´æ¥ä½¿ç”¨
                    answer = content
                else:
                    # å¦åˆ™å°è¯•ä»contentä¸­è§£ææ€è€ƒè¿‡ç¨‹
                    reasoning_content, answer = self._parse_content_tags(content)
                
                if not answer and not reasoning_content:
                    answer = str(message)
                
                return (reasoning_content or "", answer, tokens_usage)
            else:
                return ("", f"APIè¿”å›å¼‚å¸¸: {str(data)}", tokens_usage)
                
        except Exception as e:
            return ("", f"å“åº”è§£æå¤±è´¥: {e}", "")

    def _parse_stream_response(self, resp):
        """
        è§£ææµå¼å“åº”
        """
        reasoning_content = ""
        answer_content = ""
        tokens_usage = ""
        is_answering = False
        
        try:
            for line in resp.iter_lines():
                if not line:
                    continue
                    
                line_str = line.decode("utf-8").strip()
                if not line_str or line_str == "" or line_str == "data: [DONE]":
                    continue
                    
                if line_str.startswith("data: "):
                    line_str = line_str[6:]
                    if line_str.strip() == "[DONE]":
                        continue
                
                try:
                    data = json.loads(line_str)
                except Exception:
                    continue
                
                # å¤„ç†usageä¿¡æ¯
                if "usage" in data and data["usage"]:
                    tokens_usage = self._format_tokens_usage(data["usage"])
                
                # å¤„ç†choicesä¿¡æ¯
                if "choices" in data and data["choices"]:
                    delta = data["choices"][0].get("delta", {})
                    
                    # å¤„ç†æ€è€ƒè¿‡ç¨‹
                    if "reasoning_content" in delta and delta["reasoning_content"]:
                        reasoning_content += delta["reasoning_content"]
                    
                    # å¤„ç†å›å¤å†…å®¹
                    if "content" in delta and delta["content"]:
                        answer_content += delta["content"]
            
            return (reasoning_content, answer_content, tokens_usage)
            
        except Exception as e:
            return ("", f"æµå¼å“åº”è§£æå¤±è´¥: {e}", "")

    def _format_tokens_usage(self, usage):
        """
        æ ¼å¼åŒ–Tokenä½¿ç”¨ä¿¡æ¯
        """
        if not usage:
            return ""
        return f"total_tokens={usage.get('total_tokens', '-')}, input_tokens={usage.get('prompt_tokens', '-')}, output_tokens={usage.get('completion_tokens', '-')}"

    def _parse_content_tags(self, content):
        """
        è§£æcontentä¸­çš„æ ‡ç­¾ï¼ˆå…¼å®¹<think>å’Œ<answer>æ ‡ç­¾ï¼Œä¿è¯å¥å£®æ€§ï¼‰
        """
        try:
            # å°è¯•åŒ¹é…<think>æ ‡ç­¾
            pattern = r'<think>(.*?)</think>'
            match = re.search(pattern, content, re.DOTALL)
            if match:
                reasoning_content = match.group(1).strip()
                answer = content.replace(match.group(0), "").strip()
            else:
                # å°è¯•åŒ¹é…<answer>æ ‡ç­¾
                answer_match = re.search(r'<answer>(.*?)</answer>', content, re.DOTALL)
                if answer_match:
                    answer = answer_match.group(1).strip()
                    reasoning_content = ""
                else:
                    # å°è¯•åŒ¹é…ä¸å®Œæ•´çš„<answer>æ ‡ç­¾
                    answer_match = re.search(r'<answer>(.*)', content, re.DOTALL)
                    if answer_match:
                        answer = answer_match.group(1).strip()
                        reasoning_content = ""
                    else:
                        # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œæ•´ä¸ªå†…å®¹ä½œä¸ºç­”æ¡ˆ
                        answer = content.strip()
                        reasoning_content = ""
            return (reasoning_content, answer)
        except Exception as e:
            return ("", content.strip())

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "Qwen_LLM_API": QwenLLMAPI
}
NODE_DISPLAY_NAME_MAPPINGS = {
    "Qwen_LLM_API": "ğŸ¦‰Qwen LLM APIèŠ‚ç‚¹"
} 